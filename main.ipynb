{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Core (Always run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import mygene\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score, learning_curve, cross_validate, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from itertools import cycle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold, RFE, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\"\n",
    "dataset_file_name = \"dataset.pq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path_to_data + dataset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()\n",
    "\n",
    "print(f'Dataframe shape after transpose: {df.shape}')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Apply subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "excell_sheet_df = pd.read_excel('./assets/subtype_sheet.xlsx', sheet_name='RNA-Seq 1148')\n",
    "\n",
    "for sample_id in df.index:\n",
    "    print(f'Processing sample ID: {sample_id}')\n",
    "\n",
    "    if sample_id in excell_sheet_df['Sample ID'].values:\n",
    "        subtype = excell_sheet_df.loc[excell_sheet_df['Sample ID'] == sample_id, 'PAM50'].values[0]\n",
    "        print(f'Subtype found: {subtype}')\n",
    "        df.at[sample_id, 'Subtype'] = subtype\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Look for NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isna().sum().sum() > 0:\n",
    "    print(\"Dataframe contains missing values. Dropping missing values.\")\n",
    "    print(f'Number of missing values: {df.isna().sum().sum()}')\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(\"Missing values dropped.\")\n",
    "    print(f'Number of remaining missing values: {df.isna().sum().sum()}')\n",
    "else:\n",
    "    print(\"Dataframe does not contain missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Plot 1: Subtype distribution plot\n",
    "\n",
    "More info about the subtypes in this paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC6985186/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df.copy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=plot_df, x='Subtype', order=plot_df['Subtype'].value_counts().index)\n",
    "plt.title('Distribution of Subtypes')\n",
    "plt.xlabel('Subtype')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Plot 2: Scatter plot\n",
    "\n",
    "Observation: Contains a few outliers, not entirely sure what to do about them.\n",
    "\n",
    "https://stats.stackexchange.com/questions/533503/when-should-you-remove-outliers-entire-dataset-or-train-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_log_transformed = np.log1p(plot_df.select_dtypes(include=np.number))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(x_log_transformed)\n",
    "\n",
    "PCA_model = PCA(n_components=2)\n",
    "pca_result = PCA_model.fit_transform(df_scaled)\n",
    "plot_df['PCA1'] = pca_result[:, 0]\n",
    "plot_df['PCA2'] = pca_result[:, 1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=plot_df, x='PCA1', y='PCA2', hue='Subtype', palette='Set2')\n",
    "plt.title('PCA Scatter Plot Colored by Subtype')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend(title='Subtype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Plot 2.1: Scatter plot with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out outliers based on PCA1 and PCA2\n",
    "filtered_plot_df = plot_df[plot_df['PCA1'] < 2000]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_plot_df, x='PCA1', y='PCA2', hue='Subtype', palette='Set2')\n",
    "plt.title('PCA Scatter Plot with PCA1 < 2000 Colored by Subtype')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend(title='Subtype')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Stratified K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "n_jobs = -1\n",
    "\n",
    "lr_base_model = LogisticRegression(max_iter=7500, random_state=42)\n",
    "rf_base_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=n_jobs)\n",
    "xgb_base_model = XGBClassifier(objective='multi:softmax', random_state=42, n_jobs=n_jobs, eval_metric='mlogloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pipeline(model, type: str) -> Pipeline:\n",
    "    \"\"\"Returns pipeline based on model and type of feature selection. Feature selection types: rfe, sbm, skb\"\"\"\n",
    "\n",
    "    base_list = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('variance_threshold', VarianceThreshold(threshold=0.0))\n",
    "    ]\n",
    "\n",
    "    if type == 'rfe':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', RFE(estimator=LogisticRegression(max_iter=1500, random_state=42), n_features_to_select=50, step=0.1)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    elif type == 'sfm':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', SelectFromModel(estimator=RandomForestClassifier(n_estimators=100, random_state=42), max_features=50)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    elif type == 'skb':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', SelectKBest(score_func=f_classif, k=50)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature selection type. Choose from 'lr', 'rf', or 'skb'.\")\n",
    "    \n",
    "def print_score(scores):\n",
    "    print(f\"Scores for each fold: {scores}\")\n",
    "    print(f\"Average score: {np.mean(scores)}\")\n",
    "    print(f\"Standard deviation: {np.std(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(df['Subtype'])\n",
    "X = df.drop(columns=['Subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Normalization - log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log2(X + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Training Logistic Regression using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Logistic Regression - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline_rfe = setup_pipeline(model=lr_base_model, type='rfe')\n",
    "\n",
    "logreg_rfe_result = cross_validate(\n",
    "    estimator=logreg_pipeline_rfe, \n",
    "    X=X_train, \n",
    "    y=y_train, \n",
    "    cv=skf, \n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(logreg_rfe_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Logistic Regression - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline_sfm = setup_pipeline(model=lr_base_model, type='sfm')\n",
    "\n",
    "logreg_sfm_result = cross_validate(\n",
    "    estimator=logreg_pipeline_sfm,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(logreg_sfm_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Logistic Regression - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline_kbest = setup_pipeline(model=lr_base_model, type='skb')\n",
    "\n",
    "logreg_kbest_result = cross_validate(\n",
    "    estimator=logreg_pipeline_kbest,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(logreg_kbest_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Training Random Forest using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Random Forest - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline_rfe = setup_pipeline(model=rf_base_model, type='rfe')\n",
    "\n",
    "rf_rfe_result = cross_validate(\n",
    "    estimator=rf_pipeline_rfe,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(rf_rfe_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Random Forest - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline_sfm = setup_pipeline(model=rf_base_model, type='sfm')\n",
    "\n",
    "rf_sfm_result = cross_validate(\n",
    "    estimator=rf_pipeline_sfm,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(rf_sfm_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Random Forest - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline_kbest = setup_pipeline(model=rf_base_model, type='skb')\n",
    "\n",
    "rf_kbest_result = cross_validate(\n",
    "    estimator=rf_pipeline_kbest,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(rf_kbest_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Training XGBoost using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "XGBoost - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline_rfe = setup_pipeline(model=xgb_base_model, type='rfe')\n",
    "\n",
    "xgb_rfe_result = cross_validate(\n",
    "    xgb_pipeline_rfe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(xgb_rfe_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "XGBoost - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline_sfm = setup_pipeline(model=xgb_base_model, type='sfm')\n",
    "\n",
    "xgb_sfm_result = cross_validate(\n",
    "    estimator=xgb_pipeline_sfm,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(xgb_sfm_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "XGBoost - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline_kbest = setup_pipeline(model=xgb_base_model, type='skb')\n",
    "\n",
    "xgb_kbest_result = cross_validate(\n",
    "    estimator=xgb_pipeline_kbest,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(xgb_kbest_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Final training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = {\n",
    "    'logistic_regression_rfe': {\n",
    "        'result': logreg_rfe_result,\n",
    "        'base_model': lr_base_model,\n",
    "        'type': 'rfe'\n",
    "    },\n",
    "    'logistic_regression_sfm': {\n",
    "        'result': logreg_sfm_result,\n",
    "        'base_model': lr_base_model,\n",
    "        'type': 'sfm'\n",
    "    },\n",
    "    'logistic_regression_skb': {\n",
    "        'result': logreg_kbest_result,\n",
    "        'base_model': lr_base_model,\n",
    "        'type': 'skb'\n",
    "    },\n",
    "    'random_forest_rfe': {\n",
    "        'result': rf_rfe_result,\n",
    "        'base_model': rf_base_model,\n",
    "        'type': 'rfe'\n",
    "    },\n",
    "    'random_forest_sfm': {\n",
    "        'result': rf_sfm_result,\n",
    "        'base_model': rf_base_model,\n",
    "        'type': 'sfm'\n",
    "    },\n",
    "    'random_forest_skb': {\n",
    "        'result': rf_kbest_result,\n",
    "        'base_model': rf_base_model,\n",
    "        'type': 'skb'\n",
    "    },\n",
    "    'xgboost_rfe': {\n",
    "        'result': xgb_rfe_result,\n",
    "        'base_model': xgb_base_model,\n",
    "        'type': 'rfe'\n",
    "    },\n",
    "    'xgboost_sfm': {\n",
    "        'result': xgb_sfm_result,\n",
    "        'base_model': xgb_base_model,\n",
    "        'type': 'sfm'\n",
    "    },\n",
    "    'xgboost_skb': {\n",
    "        'result': xgb_kbest_result,\n",
    "        'base_model': xgb_base_model,\n",
    "        'type': 'skb'\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, data in all_scores.items():\n",
    "    val_scores = data['result']['test_score']\n",
    "    train_scores = data['result']['train_score']\n",
    "\n",
    "    mean_val_score = np.mean(val_scores)\n",
    "    std_val_score = np.std(val_scores)\n",
    "    mean_train_score = np.mean(train_scores)\n",
    "    overfitting_gap = mean_train_score - mean_val_score\n",
    "\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'mean_val_f1': mean_val_score,\n",
    "        'std_dev': std_val_score,\n",
    "        'mean_train_f1': mean_train_score,\n",
    "        'overfitting_gap': overfitting_gap\n",
    "    })\n",
    "\n",
    "report_df = pd.DataFrame(results)\n",
    "\n",
    "report_df = report_df.sort_values(by='overfitting_gap', ascending=True)\n",
    "\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(report_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "# Training Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Learning Curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = report_df.iloc[0]['model']\n",
    "\n",
    "best_pipeline = setup_pipeline(\n",
    "    model=all_scores[best_model_name]['base_model'],\n",
    "    type=all_scores[best_model_name]['type']\n",
    ")\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=best_pipeline,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5)\n",
    ")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('F1-Macro Score')\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='green', label='Cross-validation score')\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='green')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title(f'Learning Curve for Best Model: {best_model_name}')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predict_scores = cross_val_predict(\n",
    "    best_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_train, cv_predict_scores)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title(f'Confusion Matrix for Best Model: {best_model_name}')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_model = best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_proba = roc_curve_model.predict_proba(X_train)\n",
    "\n",
    "y_train_binarized = label_binarize(y_train, classes=np.arange(len(encoder.classes_)))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "\n",
    "auc_scores = []\n",
    "\n",
    "for i, (class_name, color) in enumerate(zip(encoder.classes_, colors)):\n",
    "    fpr, tpr, _ = roc_curve(y_train_binarized[:, i], y_train_proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=color, lw=2, \n",
    "             label=f'{class_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.50)')\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=13, fontweight='bold')\n",
    "plt.title('ROC Curves for Multi-Class Classification\\n(One-vs-Rest)', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [50, 75, 100]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'model__penalty': ['l1'],\n",
    "        'model__solver': ['saga'],\n",
    "        'model__C': [0.01, 0.1, 1, 10, 50],\n",
    "        'model__class_weight': ['balanced', None]\n",
    "    },\n",
    "    {\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs', 'newton-cg', 'newton-cholesky'],\n",
    "        'model__C': [0.01, 0.1, 1, 10, 50],\n",
    "        'model__class_weight': ['balanced', None]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Insert N feature based on feature selection method\n",
    "for grid in param_grid:\n",
    "    if all_scores[best_model_name]['type'] == 'rfe':\n",
    "        grid['feature_selection__n_features_to_select'] = n_features\n",
    "    elif all_scores[best_model_name]['type'] == 'sfm':\n",
    "        grid['feature_selection__max_features'] = n_features\n",
    "    elif all_scores[best_model_name]['type'] == 'skb':\n",
    "        grid['feature_selection__k'] = n_features\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature selection type. Choose from 'rfe', 'sfm', or 'skb'.\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=best_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best F1-Macro Score: {grid_search.best_score_:.4f}\")\n",
    "print(\"Best Parameters Found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "Learning curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=best_model,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5)\n",
    ")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('F1-Macro Score')\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='green', label='Cross-validation score')\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='green')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title(f'Learning Curve for Best Model: {best_model_name}')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predict_scores = cross_val_predict(\n",
    "    best_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_train, cv_predict_scores)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title(f'Confusion Matrix for Best Model: {best_model_name}')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_model = best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_proba = roc_curve_model.predict_proba(X_train)\n",
    "\n",
    "y_train_binarized = label_binarize(y_train, classes=np.arange(len(encoder.classes_)))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "\n",
    "auc_scores = []\n",
    "\n",
    "for i, (class_name, color) in enumerate(zip(encoder.classes_, colors)):\n",
    "    fpr, tpr, _ = roc_curve(y_train_binarized[:, i], y_train_proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=color, lw=2, \n",
    "             label=f'{class_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.50)')\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=13, fontweight='bold')\n",
    "plt.title('ROC Curves for Multi-Class Classification\\n(One-vs-Rest)', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "# Shap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_step = best_model.named_steps['scaler']\n",
    "vt_step = best_model.named_steps['variance_threshold']\n",
    "selector_step = best_model.named_steps['feature_selection']\n",
    "model_step = best_model.named_steps['model']\n",
    "\n",
    "gene_ids_array = np.array(X_train.columns)\n",
    "\n",
    "vt_mask = vt_step.get_support()\n",
    "genes_after_vt = gene_ids_array[vt_mask]\n",
    "\n",
    "skb_mask = selector_step.get_support()\n",
    "final_selected_gene_ids = genes_after_vt[skb_mask]\n",
    "\n",
    "final_selected_gene_ids_transformed = [gene_id.split('.')[0] for gene_id in final_selected_gene_ids]\n",
    "\n",
    "mg = mygene.MyGeneInfo()\n",
    "query_results = mg.querymany(\n",
    "    final_selected_gene_ids_transformed,\n",
    "    scopes='ensembl.gene', \n",
    "    fields='symbol', \n",
    "    species='human',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "gene_symbol_mapping = {res['query']: res.get('symbol', res['query']) for res in query_results}\n",
    "final_feature_names = [gene_symbol_mapping.get(gene_id.split('.')[0]) for gene_id in final_selected_gene_ids]\n",
    "\n",
    "X_train_scaled = scaler_step.transform(X_train)\n",
    "X_train_vt = vt_step.transform(X_train_scaled)\n",
    "X_train_transformed = selector_step.transform(X_train_vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model_step, X_train_transformed)\n",
    "shap_values = explainer(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_importance_score = np.abs(shap_values.values).mean(axis=0).sum(axis=1)\n",
    "\n",
    "feature_importance_series = pd.Series(global_importance_score, index=final_feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 Important Features based on SHAP values:\")\n",
    "print(feature_importance_series.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "Simple ROPN1 Influence by Subtype - Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ropn1_idx = final_feature_names.index('ROPN1')\n",
    "class_names = encoder.classes_\n",
    "\n",
    "influence_scores = []\n",
    "for class_idx in range(len(class_names)):\n",
    "    shap_vals = shap_values[:, class_idx, ropn1_idx].values\n",
    "    influence_scores.append(np.mean(np.abs(shap_vals)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "bars = plt.bar(class_names, influence_scores, color=colors, edgecolor='black', linewidth=2)\n",
    "\n",
    "for bar, value in zip(bars, influence_scores):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{value:.4f}',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.ylabel('Mean Absolute SHAP Value\\n(Influence Strength)', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Subtype', fontsize=13, fontweight='bold')\n",
    "plt.title('ROPN1 Gene: Influence by Cancer Subtype', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"ROPN1 Influence Ranking:\")\n",
    "print(\"-\" * 40)\n",
    "ranking = sorted(zip(class_names, influence_scores), key=lambda x: x[1], reverse=True)\n",
    "for rank, (subtype, score) in enumerate(ranking, 1):\n",
    "    print(f\"{rank}. {subtype:10s}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ HIGHEST influence: {ranking[0][0]} ({ranking[0][1]:.4f})\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
