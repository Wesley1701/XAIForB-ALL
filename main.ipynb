{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Core (Always run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import mygene\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score, learning_curve, cross_validate, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from itertools import cycle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold, RFE, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\"\n",
    "dataset_file_name = \"dataset.pq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path_to_data + dataset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()\n",
    "\n",
    "print(f'Dataframe shape after transpose: {df.shape}')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Apply subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "excell_sheet_df = pd.read_excel('./assets/subtype_sheet.xlsx', sheet_name='RNA-Seq 1148')\n",
    "\n",
    "for sample_id in df.index:\n",
    "    print(f'Processing sample ID: {sample_id}')\n",
    "\n",
    "    if sample_id in excell_sheet_df['Sample ID'].values:\n",
    "        subtype = excell_sheet_df.loc[excell_sheet_df['Sample ID'] == sample_id, 'PAM50'].values[0]\n",
    "        print(f'Subtype found: {subtype}')\n",
    "        df.at[sample_id, 'Subtype'] = subtype\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Look for NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isna().sum().sum() > 0:\n",
    "    print(\"Dataframe contains missing values. Dropping missing values.\")\n",
    "    print(f'Number of missing values: {df.isna().sum().sum()}')\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(\"Missing values dropped.\")\n",
    "    print(f'Number of remaining missing values: {df.isna().sum().sum()}')\n",
    "else:\n",
    "    print(\"Dataframe does not contain missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Plot 1: Subtype distribution plot\n",
    "\n",
    "More info about the subtypes in this paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC6985186/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df.copy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=plot_df, x='Subtype', order=plot_df['Subtype'].value_counts().index)\n",
    "plt.title('Distribution of Subtypes')\n",
    "plt.xlabel('Subtype')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Plot 2: Scatter plot\n",
    "\n",
    "Observation: Contains a few outliers, not entirely sure what to do about them.\n",
    "\n",
    "https://stats.stackexchange.com/questions/533503/when-should-you-remove-outliers-entire-dataset-or-train-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_log_transformed = np.log1p(plot_df.select_dtypes(include=np.number))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(x_log_transformed)\n",
    "\n",
    "PCA_model = PCA(n_components=2)\n",
    "pca_result = PCA_model.fit_transform(df_scaled)\n",
    "plot_df['PCA1'] = pca_result[:, 0]\n",
    "plot_df['PCA2'] = pca_result[:, 1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=plot_df, x='PCA1', y='PCA2', hue='Subtype', palette='Set2')\n",
    "plt.title('PCA Scatter Plot Colored by Subtype')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend(title='Subtype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Plot 2.1: Scatter plot with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out outliers based on PCA1 and PCA2\n",
    "filtered_plot_df = plot_df[plot_df['PCA1'] < 2000]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_plot_df, x='PCA1', y='PCA2', hue='Subtype', palette='Set2')\n",
    "plt.title('PCA Scatter Plot with PCA1 < 2000 Colored by Subtype')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend(title='Subtype')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Stratified K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "n_jobs = -1\n",
    "\n",
    "lr_base_model = LogisticRegression(max_iter=7500, random_state=42)\n",
    "rf_base_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=n_jobs)\n",
    "xgb_base_model = XGBClassifier(objective='multi:softmax', random_state=42, n_jobs=n_jobs, eval_metric='mlogloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pipeline(model, type: str) -> Pipeline:\n",
    "    \"\"\"Returns pipeline based on model and type of feature selection. Feature selection types: rfe, sbm, skb\"\"\"\n",
    "\n",
    "    base_list = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('variance_threshold', VarianceThreshold(threshold=0.0))\n",
    "    ]\n",
    "\n",
    "    if type == 'rfe':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', RFE(estimator=LogisticRegression(max_iter=1500, random_state=42), n_features_to_select=50, step=0.1)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    elif type == 'sbm':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', SelectFromModel(estimator=RandomForestClassifier(n_estimators=100, random_state=42), max_features=50)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    elif type == 'skb':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', SelectKBest(score_func=f_classif, k=50)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature selection type. Choose from 'lr', 'rf', or 'skb'.\")\n",
    "    \n",
    "def print_score(scores):\n",
    "    print(f\"Scores for each fold: {scores}\")\n",
    "    print(f\"Average score: {np.mean(scores)}\")\n",
    "    print(f\"Standard deviation: {np.std(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(df['Subtype'])\n",
    "X = df.drop(columns=['Subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Normalization - log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log2(X + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Training Logistic Regression using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Logistic Regression - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline_rfe = setup_pipeline(model=lr_base_model, type='rfe')\n",
    "\n",
    "logreg_rfe_result = cross_validate(\n",
    "    estimator=logreg_pipeline_rfe, \n",
    "    X=X_train, \n",
    "    y=y_train, \n",
    "    cv=skf, \n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(logreg_rfe_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Logistic Regression - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_classifier_sbm = setup_pipeline(model=LogisticRegression(max_iter=1500, random_state=42), type='sbm').fit(X_train, y_train)\n",
    "# logreg_predictions_sbm = logreg_classifier_sbm.predict(X_test)\n",
    "\n",
    "# accuracy_logreg_sbm = accuracy_score(y_test, logreg_predictions_sbm)\n",
    "\n",
    "# print(f'Logistic Regression with SBM Feature Selection Accuracy: {accuracy_logreg_sbm:.4f}')\n",
    "\n",
    "logreg_pipeline_sbm = setup_pipeline(model=lr_base_model, type='sbm')\n",
    "\n",
    "logreg_sbm_result = cross_validate(\n",
    "    estimator=logreg_pipeline_sbm,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(logreg_sbm_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Logistic Regression - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_classifier_kbest = setup_pipeline(model=LogisticRegression(max_iter=1500, random_state=42), type='skb').fit(X_train, y_train)\n",
    "# logreg_predictions_kbest = logreg_classifier_kbest.predict(X_test)\n",
    "\n",
    "# accuracy_logreg_kbest = accuracy_score(y_test, logreg_predictions_kbest)\n",
    "\n",
    "# print(f'Logistic Regression with KBest Feature Selection Accuracy: {accuracy_logreg_kbest:.4f}')\n",
    "\n",
    "logreg_pipeline_kbest = setup_pipeline(model=lr_base_model, type='skb')\n",
    "\n",
    "logreg_kbest_result = cross_validate(\n",
    "    estimator=logreg_pipeline_kbest,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(logreg_kbest_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Training Random Forest using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Random Forest - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_classifier_rfe = setup_pipeline(model=RandomForestClassifier(n_estimators=100, random_state=42), type='rfe').fit(X_train, y_train)\n",
    "# rf_predictions_rfe = rf_classifier_rfe.predict(X_test)\n",
    "\n",
    "# accuracy_rf_rfe = accuracy_score(y_test, rf_predictions_rfe)\n",
    "\n",
    "# print(f'Random Forest with RFE Feature Selection Accuracy: {accuracy_rf_rfe:.4f}')\n",
    "\n",
    "rf_pipeline_rfe = setup_pipeline(model=rf_base_model, type='rfe')\n",
    "\n",
    "rf_rfe_result = cross_validate(\n",
    "    estimator=rf_pipeline_rfe,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(rf_rfe_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Random Forest - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_classifier_sbm = setup_pipeline(model=RandomForestClassifier(n_estimators=100, random_state=42), type='sbm').fit(X_train, y_train)\n",
    "# rf_predictions_sbm = rf_classifier_sbm.predict(X_test)\n",
    "\n",
    "# accuracy_rf_sbm = accuracy_score(y_test, rf_predictions_sbm)\n",
    "\n",
    "# print(f'Random Forest with SBM Feature Selection Accuracy: {accuracy_rf_sbm:.4f}')\n",
    "\n",
    "rf_pipeline_sbm = setup_pipeline(model=rf_base_model, type='sbm')\n",
    "\n",
    "rf_sbm_result = cross_validate(\n",
    "    estimator=rf_pipeline_sbm,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(rf_sbm_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Random Forest - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_classifier_kbest = setup_pipeline(model=RandomForestClassifier(n_estimators=100, random_state=42), type='skb').fit(X_train, y_train)\n",
    "# rf_predictions_kbest = rf_classifier_kbest.predict(X_test)\n",
    "\n",
    "# accuracy_rf_kbest = accuracy_score(y_test, rf_predictions_kbest)\n",
    "\n",
    "# print(f'Random Forest with KBest Feature Selection Accuracy: {accuracy_rf_kbest:.4f}')\n",
    "\n",
    "rf_pipeline_kbest = setup_pipeline(model=rf_base_model, type='skb')\n",
    "\n",
    "rf_kbest_result = cross_validate(\n",
    "    estimator=rf_pipeline_kbest,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(rf_kbest_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Training XGBoost using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "XGBoost - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_classifier_rfe = setup_pipeline(model=XGBClassifier(eval_metric='mlogloss', random_state=42), type='rfe').fit(X_train, y_train)\n",
    "# xgb_predictions_rfe = xgb_classifier_rfe.predict(X_test)\n",
    "\n",
    "# accuracy_xgb_rfe = accuracy_score(y_test, xgb_predictions_rfe)\n",
    "\n",
    "# print(f'XGBoost with RFE Feature Selection Accuracy: {accuracy_xgb_rfe:.4f}')\n",
    "\n",
    "xgb_pipeline_rfe = setup_pipeline(model=xgb_base_model, type='rfe')\n",
    "\n",
    "xgb_rfe_result = cross_validate(\n",
    "    xgb_pipeline_rfe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(xgb_rfe_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "XGBoost - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_classifier_sbm = setup_pipeline(model=XGBClassifier(eval_metric='mlogloss', random_state=42), type='sbm').fit(X_train, y_train)\n",
    "# xgb_predictions_sbm = xgb_classifier_sbm.predict(X_test)\n",
    "\n",
    "# accuracy_xgb_sbm = accuracy_score(y_test, xgb_predictions_sbm)\n",
    "\n",
    "# print(f'XGBoost with SBM Feature Selection Accuracy: {accuracy_xgb_sbm:.4f}')\n",
    "\n",
    "xgb_pipeline_sbm = setup_pipeline(model=xgb_base_model, type='sbm')\n",
    "\n",
    "xgb_sbm_result = cross_validate(\n",
    "    estimator=xgb_pipeline_sbm,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(xgb_sbm_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "XGBoost - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_classifier_skbest = setup_pipeline(model=XGBClassifier(eval_metric='mlogloss', random_state=42), type='skb').fit(X_train, y_train)\n",
    "# xgb_predictions_kbest = xgb_classifier_skbest.predict(X_test)\n",
    "\n",
    "# accuracy_xgb_kbest = accuracy_score(y_test, xgb_predictions_kbest)\n",
    "\n",
    "# print(f'XGBoost with SKB Feature Selection Accuracy: {accuracy_xgb_kbest:.4f}')\n",
    "\n",
    "xgb_pipeline_kbest = setup_pipeline(model=xgb_base_model, type='skb')\n",
    "\n",
    "xgb_kbest_result = cross_validate(\n",
    "    estimator=xgb_pipeline_kbest,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print_score(xgb_kbest_result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Final training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = {\n",
    "    'logistic_regression_rfe': {\n",
    "        'result': logreg_rfe_result,\n",
    "        'base_model': lr_base_model,\n",
    "        'type': 'rfe'\n",
    "    },\n",
    "    'logistic_regression_sbm': {\n",
    "        'result': logreg_sbm_result,\n",
    "        'base_model': lr_base_model,\n",
    "        'type': 'sbm'\n",
    "    },\n",
    "    'logistic_regression_skb': {\n",
    "        'result': logreg_kbest_result,\n",
    "        'base_model': lr_base_model,\n",
    "        'type': 'skb'\n",
    "    },\n",
    "    'random_forest_rfe': {\n",
    "        'result': rf_rfe_result,\n",
    "        'base_model': rf_base_model,\n",
    "        'type': 'rfe'\n",
    "    },\n",
    "    'random_forest_sbm': {\n",
    "        'result': rf_sbm_result,\n",
    "        'base_model': rf_base_model,\n",
    "        'type': 'sbm'\n",
    "    },\n",
    "    'random_forest_skb': {\n",
    "        'result': rf_kbest_result,\n",
    "        'base_model': rf_base_model,\n",
    "        'type': 'skb'\n",
    "    },\n",
    "    'xgboost_rfe': {\n",
    "        'result': xgb_rfe_result,\n",
    "        'base_model': xgb_base_model,\n",
    "        'type': 'rfe'\n",
    "    },\n",
    "    'xgboost_sbm': {\n",
    "        'result': xgb_sbm_result,\n",
    "        'base_model': xgb_base_model,\n",
    "        'type': 'sbm'\n",
    "    },\n",
    "    'xgboost_skb': {\n",
    "        'result': xgb_kbest_result,\n",
    "        'base_model': xgb_base_model,\n",
    "        'type': 'skb'\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, data in all_scores.items():\n",
    "    val_scores = data['result']['test_score']\n",
    "    train_scores = data['result']['train_score']\n",
    "\n",
    "    mean_val_score = np.mean(val_scores)\n",
    "    std_val_score = np.std(val_scores)\n",
    "    mean_train_score = np.mean(train_scores)\n",
    "    overfitting_gap = mean_train_score - mean_val_score\n",
    "\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'mean_val_f1': mean_val_score,\n",
    "        'std_dev': std_val_score,\n",
    "        'mean_train_f1': mean_train_score,\n",
    "        'overfitting_gap': overfitting_gap\n",
    "    })\n",
    "\n",
    "report_df = pd.DataFrame(results)\n",
    "\n",
    "report_df = report_df.sort_values(by='overfitting_gap', ascending=True)\n",
    "\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(report_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "# Training Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Learning Curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = report_df.iloc[0]['model']\n",
    "\n",
    "best_pipeline = setup_pipeline(\n",
    "    model=all_scores[best_model_name]['base_model'],\n",
    "    type=all_scores[best_model_name]['type']\n",
    ")\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=best_pipeline,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5)\n",
    ")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('F1-Macro Score')\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='green', label='Cross-validation score')\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='green')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title(f'Learning Curve for Best Model: {best_model_name}')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predict_scores = cross_val_predict(\n",
    "    best_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_train, cv_predict_scores)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title(f'Confusion Matrix for Best Model: {best_model_name}')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [50, 75, 100]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'model__penalty': ['l1'],\n",
    "        'model__solver': ['saga'],\n",
    "        'model__C': [0.01, 0.1, 1, 10, 50],\n",
    "        'model__class_weight': ['balanced', None]\n",
    "    },\n",
    "    {\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs', 'newton-cg', 'newton-cholesky'],\n",
    "        'model__C': [0.01, 0.1, 1, 10, 50],\n",
    "        'model__class_weight': ['balanced', None]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Insert N feature based on feature selection method\n",
    "for grid in param_grid:\n",
    "    if all_scores[best_model_name]['type'] == 'rfe':\n",
    "        grid['feature_selection__n_features_to_select'] = n_features\n",
    "    elif all_scores[best_model_name]['type'] == 'sbm':\n",
    "        grid['feature_selection__max_features'] = n_features\n",
    "    elif all_scores[best_model_name]['type'] == 'skb':\n",
    "        grid['feature_selection__k'] = n_features\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature selection type. Choose from 'rfe', 'sbm', or 'skb'.\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=best_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best F1-Macro Score: {grid_search.best_score_:.4f}\")\n",
    "print(\"Best Parameters Found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "Learning curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=best_model,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5)\n",
    ")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('F1-Macro Score')\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='green', label='Cross-validation score')\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='blue')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='green')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title(f'Learning Curve for Best Model: {best_model_name}')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_predict_scores = cross_val_predict(\n",
    "    best_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_train, cv_predict_scores)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title(f'Confusion Matrix for Best Model: {best_model_name}')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "# Shap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_step = best_model.named_steps['scaler']\n",
    "vt_step = best_model.named_steps['variance_threshold']\n",
    "selector_step = best_model.named_steps['feature_selection']\n",
    "model_step = best_model.named_steps['model']\n",
    "\n",
    "gene_ids_array = np.array(X_train.columns)\n",
    "\n",
    "vt_mask = vt_step.get_support()\n",
    "genes_after_vt = gene_ids_array[vt_mask]\n",
    "\n",
    "skb_mask = selector_step.get_support()\n",
    "final_selected_gene_ids = genes_after_vt[skb_mask]\n",
    "\n",
    "final_selected_gene_ids_transformed = [gene_id.split('.')[0] for gene_id in final_selected_gene_ids]\n",
    "\n",
    "mg = mygene.MyGeneInfo()\n",
    "query_results = mg.querymany(\n",
    "    final_selected_gene_ids_transformed,\n",
    "    scopes='ensembl.gene', \n",
    "    fields='symbol', \n",
    "    species='human',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "gene_symbol_mapping = {res['query']: res.get('symbol', res['query']) for res in query_results}\n",
    "final_feature_names = [gene_symbol_mapping.get(gene_id.split('.')[0]) for gene_id in final_selected_gene_ids]\n",
    "\n",
    "X_train_scaled = scaler_step.transform(X_train)\n",
    "X_train_vt = vt_step.transform(X_train_scaled)\n",
    "X_train_transformed = selector_step.transform(X_train_vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model_step, X_train_transformed)\n",
    "shap_values = explainer(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_importance_score = np.abs(shap_values.values).mean(axis=0).sum(axis=1)\n",
    "\n",
    "feature_importance_series = pd.Series(global_importance_score, index=final_feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 Important Features based on SHAP values:\")\n",
    "print(feature_importance_series.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "Simple ROPN1 Influence by Subtype - Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ropn1_idx = final_feature_names.index('ROPN1')\n",
    "class_names = encoder.classes_\n",
    "\n",
    "influence_scores = []\n",
    "for class_idx in range(len(class_names)):\n",
    "    shap_vals = shap_values[:, class_idx, ropn1_idx].values\n",
    "    influence_scores.append(np.mean(np.abs(shap_vals)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "bars = plt.bar(class_names, influence_scores, color=colors, edgecolor='black', linewidth=2)\n",
    "\n",
    "for bar, value in zip(bars, influence_scores):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{value:.4f}',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.ylabel('Mean Absolute SHAP Value\\n(Influence Strength)', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Subtype', fontsize=13, fontweight='bold')\n",
    "plt.title('ROPN1 Gene: Influence by Cancer Subtype', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"ROPN1 Influence Ranking:\")\n",
    "print(\"-\" * 40)\n",
    "ranking = sorted(zip(class_names, influence_scores), key=lambda x: x[1], reverse=True)\n",
    "for rank, (subtype, score) in enumerate(ranking, 1):\n",
    "    print(f\"{rank}. {subtype:10s}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ HIGHEST influence: {ranking[0][0]} ({ranking[0][1]:.4f})\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "Biological check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_gene_names = X.columns\n",
    "\n",
    "# pam50_list = [\n",
    "#     \"UBE2T\", \"BIRC5\", \"NUF2\", \"CDC6\", \"CCNB1\", \"TYMS\", \"MYBL2\", \"CEP55\", \n",
    "#     \"MELK\", \"NDC80\", \"RRM2\", \"UBE2C\", \"CENPF\", \"PTTG1\", \"EXO1\", \"ORC6L\", \n",
    "#     \"ANLN\", \"CCNE1\", \"CDC20\", \"MKI67\", \"KIF2C\", \"ACTR3B\", \"MYC\", \"EGFR\", \n",
    "#     \"KRT5\", \"PHGDH\", \"CDH3\", \"MIA\", \"KRT17\", \"FOXC1\", \"SFRP1\", \"KRT14\", \n",
    "#     \"ESR1\", \"SLC39A6\", \"BAG1\", \"MAPT\", \"PGR\", \"CXXC5\", \"MLPH\", \"BCL2\", \n",
    "#     \"MDM2\", \"NAT1\", \"FOXA1\", \"BLVRA\", \"MMP11\", \"GPR160\", \"FGFR4\", \"GRB7\", \n",
    "#     \"TMEM45B\", \"ERBB2\"\n",
    "# ]\n",
    "\n",
    "# pam50_set = set(pam50_list)\n",
    "\n",
    "# selector = best_model.named_steps['feature_selection']\n",
    "# lr_model = best_model.named_steps['model']\n",
    "\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "# print(f\"Selected {len(selected_indices)} feature indices\")\n",
    "\n",
    "# selected_gene_names = [all_gene_names[i] for i in selected_indices]\n",
    "# print(f\"Selected {len(selected_gene_names)} genes\")\n",
    "\n",
    "# # Modify to look for symbols instead of Ensembl IDs with version numbers\n",
    "# selected_gene_names_modified = [gene.split('.')[0] for gene in selected_gene_names]\n",
    "# print(f\"Selected gene names after removing version numbers: {selected_gene_names_modified[:10]}\")\n",
    "\n",
    "# mg = mygene.MyGeneInfo()\n",
    "# gene_info = mg.querymany(\n",
    "#     selected_gene_names_modified,\n",
    "#     scopes='ensembl.gene',\n",
    "#     fields='symbol',\n",
    "#     species='human',\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# # Print first 5 entries of gene_info for verification\n",
    "# print(gene_info[:5])\n",
    "\n",
    "# ensembl_to_symbol = {}\n",
    "# for result in gene_info:\n",
    "#     ensembl_id = result['query']\n",
    "#     gene_symbol = result.get('symbol', ensembl_id)\n",
    "#     ensembl_to_symbol[ensembl_id] = gene_symbol\n",
    "\n",
    "# gene_symbols = [ensembl_to_symbol.get(gene, gene) for gene in selected_gene_names_modified]\n",
    "\n",
    "# # Identify PAM50 genes in the selected genes\n",
    "# pam50_selected_genes = [gene for gene in gene_symbols if gene in pam50_set]\n",
    "\n",
    "# print(gene_symbols)\n",
    "# print(pam50_set)\n",
    "# print(pam50_set.intersection(set(gene_symbols)))\n",
    "\n",
    "# print(f\"Number of PAM50 genes selected: {len(pam50_selected_genes)}\")\n",
    "# print(\"PAM50 genes selected:\")\n",
    "# for gene in pam50_selected_genes:\n",
    "#     print(gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "# TRAINING LEGACY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard_scaler = StandardScaler()\n",
    "# X_train_scaled = standard_scaler.fit_transform(X_train)\n",
    "# X_test_scaled = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance_filter = VarianceThreshold(threshold=0.1)\n",
    "# X_train_filtered = variance_filter.fit_transform(X_train_scaled)\n",
    "# X_test_filtered = variance_filter.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "Feature selection (SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest_model = SelectKBest(score_func=f_classif, k=50)\n",
    "# X_train_selected = SelectKBest_model.fit_transform(X_train_filtered, y_train)\n",
    "# X_test_selected = SelectKBest_model.transform(X_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_rf = rf_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# print(f'Random Forest Classifier Accuracy: {accuracy_rf:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_classifier = LogisticRegression(max_iter=1500, random_state=42)\n",
    "# logreg_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_lr = logreg_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# print(f'Logistic Regression Classifier Accuracy: {accuracy_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "XGBoost\n",
    "\n",
    "Parameters for XGBClassifier: https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_classifier = XGBClassifier(\n",
    "#     tree_method='auto',\n",
    "#     n_estimators=100,\n",
    "#     eval_metric='mlogloss', \n",
    "#     random_state=42,\n",
    "#     max_depth=6,\n",
    "# )\n",
    "# xgb_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_xgb = xgb_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "# print(f'XGBoost Classifier Accuracy: {accuracy_xgb:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "# Training Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "## Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_classification_report(y_true, y_pred):\n",
    "#     report = classification_report(\n",
    "#         y_true,\n",
    "#         y_pred\n",
    "#     )\n",
    "#     print(\"Classification Report:\")\n",
    "#     print(report)\n",
    "\n",
    "# def generate_confusion_matrix(y_true, y_pred, class_names, title_additional=\"\"):\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('True')\n",
    "#     if title_additional:\n",
    "#         plt.title(f'Confusion Matrix - {title_additional}')\n",
    "#     else:\n",
    "#         plt.title('Confusion Matrix')\n",
    "#     plt.show()\n",
    "\n",
    "# def plot_cm_on_ax(ax, y_true, y_pred, class_names, title=\"\"):\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "#     sns.heatmap(cm, \n",
    "#                 annot=True, \n",
    "#                 fmt='d', \n",
    "#                 cmap='Blues', \n",
    "#                 xticklabels=class_names, \n",
    "#                 yticklabels=class_names,\n",
    "#                 ax=ax,          # <<< Plots on the provided subplot\n",
    "#                 cbar=True)      # You can set this to False if you want\n",
    "    \n",
    "#     ax.set_xlabel('Predicted')\n",
    "#     ax.set_ylabel('True')\n",
    "#     ax.set_title(title, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "### Classification Reports - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_titles = ['Model (LR-RFE)', 'Model (RF-Select)', 'Model (KBest)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds_lr = [logreg_predictions_rfe, logreg_predictions_sbm, logreg_predictions_kbest]\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 6))\n",
    "\n",
    "# for ax, y_pred, title in zip(axes, all_preds_lr, all_titles):\n",
    "#     plot_cm_on_ax(ax, \n",
    "#                   y_true=y_test, \n",
    "#                   y_pred=y_pred, \n",
    "#                   class_names=encoder.classes_, \n",
    "#                   title=title\n",
    "#                 )\n",
    "\n",
    "# fig.suptitle('Logistic Regression Model - Feature Selection', fontsize=20, y=1.05)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "### Classification Reports - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds_rf = [rf_predictions_rfe, rf_predictions_sbm, rf_predictions_kbest]\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 6))\n",
    "\n",
    "# for ax, y_pred, title in zip(axes, all_preds_rf, all_titles):\n",
    "#     plot_cm_on_ax(ax, \n",
    "#                   y_true=y_test, \n",
    "#                   y_pred=y_pred, \n",
    "#                   class_names=encoder.classes_, \n",
    "#                   title=title\n",
    "#                 )\n",
    "\n",
    "# fig.suptitle('Random Forest Model - Feature Selection', fontsize=20, y=1.05)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "### Classification Reports - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds_xgb = [xgb_predictions_rfe, xgb_predictions_sbm, xgb_predictions_kbest]\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 6))\n",
    "# for ax, y_pred, title in zip(axes, all_preds_xgb, all_titles):\n",
    "#     plot_cm_on_ax(ax, \n",
    "#                   y_true=y_test, \n",
    "#                   y_pred=y_pred, \n",
    "#                   class_names=encoder.classes_, \n",
    "#                   title=title\n",
    "#                 )\n",
    "\n",
    "# fig.suptitle('XGBoost Model - Feature Selection', fontsize=20, y=1.05)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "## Train ACC vs Test ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_acc_compare(model, X_train, y_train, y_test, y_pred):\n",
    "#     acc_score = accuracy_score(y_test, y_pred)\n",
    "#     train_pred = model.predict(X_train)\n",
    "#     train_f1 = f1_score(y_train, train_pred, average='weighted')\n",
    "#     test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "#     print(f'Model name: {model.named_steps[\"model\"].__class__.__name__}')\n",
    "#     print(f'Feature Selection Method: {model.named_steps[\"feature_selection\"].__class__.__name__}')\n",
    "#     print('---')\n",
    "#     print(f'Accuracy Score: {acc_score:.4f}')\n",
    "#     print('---')\n",
    "#     print(f'Training F1 Score: {train_f1:.4f}')\n",
    "#     print(f'Testing F1 Score: {test_f1:.4f}')\n",
    "#     print(f'F1 Score Difference (Train - Test): {train_f1 - test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_acc_compare(logreg_classifier_rfe, X_train, y_train, y_test, logreg_predictions_rfe)\n",
    "# print(\"\\n\")\n",
    "# train_test_acc_compare(logreg_classifier_sbm, X_train, y_train, y_test, logreg_predictions_sbm)\n",
    "# print(\"\\n\")\n",
    "# train_test_acc_compare(logreg_classifier_kbest, X_train, y_train, y_test, logreg_predictions_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_acc_compare(rf_classifier_rfe, X_train, y_train, y_test, rf_predictions_rfe)\n",
    "# print(\"\\n\")\n",
    "# train_test_acc_compare(rf_classifier_sbm, X_train, y_train, y_test, rf_predictions_sbm)\n",
    "# print(\"\\n\")\n",
    "# train_test_acc_compare(rf_classifier_kbest, X_train, y_train, y_test, rf_predictions_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_acc_compare(xgb_classifier_rfe, X_train, y_train, y_test, xgb_predictions_rfe)\n",
    "# print(\"\\n\")\n",
    "# train_test_acc_compare(xgb_classifier_sbm, X_train, y_train, y_test, xgb_predictions_sbm)\n",
    "# print(\"\\n\")\n",
    "# train_test_acc_compare(xgb_classifier_skbest, X_train, y_train, y_test, xgb_predictions_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "## Tuning process\n",
    "\n",
    "Possible scoring values are: 'accuracy', 'f1_macro', 'f1_weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring = 'f1_macro' # metric for evaluation\n",
    "# n_features = [50, 75, 100]\n",
    "# n_jobs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_sbm_pipeline = setup_pipeline(model=LogisticRegression(max_iter=7500, random_state=42), type='sbm')\n",
    "\n",
    "# param_grid_logreg_sbm = [\n",
    "#     {\n",
    "#         'feature_selection__max_features': n_features,\n",
    "#         'model__penalty': ['l1'],\n",
    "#         'model__solver': ['saga'],\n",
    "#         'model__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "#         'model__class_weight': ['balanced']\n",
    "#     },\n",
    "#     {\n",
    "#         'feature_selection__max_features': n_features,\n",
    "#         'model__penalty': ['l2'],\n",
    "#         'model__solver': ['lbfgs', 'newton-cg', 'newton-cholesky'],\n",
    "#         'model__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "#         'model__class_weight': ['balanced']\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# grid_search_logreg_sbm = GridSearchCV(estimator=logreg_sbm_pipeline, param_grid=param_grid_logreg_sbm, scoring=scoring, cv=5, n_jobs=n_jobs, verbose=2)\n",
    "\n",
    "# grid_search_logreg_sbm.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Best parameters for Logistic Regression with SBM: {grid_search_logreg_sbm.best_params_}')\n",
    "# print(f'Best {scoring} score for Logistic Regression with SBM: {grid_search_logreg_sbm.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = grid_search_logreg_sbm.best_estimator_\n",
    "\n",
    "# all_gene_names = X.columns\n",
    "\n",
    "# pam50_list = [\n",
    "#     \"UBE2T\", \"BIRC5\", \"NUF2\", \"CDC6\", \"CCNB1\", \"TYMS\", \"MYBL2\", \"CEP55\", \n",
    "#     \"MELK\", \"NDC80\", \"RRM2\", \"UBE2C\", \"CENPF\", \"PTTG1\", \"EXO1\", \"ORC6L\", \n",
    "#     \"ANLN\", \"CCNE1\", \"CDC20\", \"MKI67\", \"KIF2C\", \"ACTR3B\", \"MYC\", \"EGFR\", \n",
    "#     \"KRT5\", \"PHGDH\", \"CDH3\", \"MIA\", \"KRT17\", \"FOXC1\", \"SFRP1\", \"KRT14\", \n",
    "#     \"ESR1\", \"SLC39A6\", \"BAG1\", \"MAPT\", \"PGR\", \"CXXC5\", \"MLPH\", \"BCL2\", \n",
    "#     \"MDM2\", \"NAT1\", \"FOXA1\", \"BLVRA\", \"MMP11\", \"GPR160\", \"FGFR4\", \"GRB7\", \n",
    "#     \"TMEM45B\", \"ERBB2\"\n",
    "# ]\n",
    "\n",
    "# pam50_set = set(pam50_list)\n",
    "\n",
    "# selector = best_model.named_steps['feature_selection']\n",
    "# lr_model = best_model.named_steps['model']\n",
    "\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "# print(f\"Selected {len(selected_indices)} feature indices\")\n",
    "\n",
    "# selected_gene_names = [all_gene_names[i] for i in selected_indices]\n",
    "# print(f\"Selected {len(selected_gene_names)} genes\")\n",
    "\n",
    "# # Modify to look for symbols instead of Ensembl IDs with version numbers\n",
    "# selected_gene_names = [gene.split('.')[0] for gene in selected_gene_names]\n",
    "# print(f\"Selected gene names after removing version numbers: {selected_gene_names[:10]}\")\n",
    "\n",
    "# mg = mygene.MyGeneInfo()\n",
    "# gene_info = mg.querymany(\n",
    "#     selected_gene_names,\n",
    "#     scopes='ensembl.gene',\n",
    "#     fields='symbol',\n",
    "#     species='human',\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# # Print first 5 entries of gene_info for verification\n",
    "# print(gene_info[:5])\n",
    "\n",
    "# ensembl_to_symbol = {}\n",
    "# for result in gene_info:\n",
    "#     ensembl_id = result['query']\n",
    "#     gene_symbol = result.get('symbol', ensembl_id)\n",
    "#     ensembl_to_symbol[ensembl_id] = gene_symbol\n",
    "\n",
    "# gene_symbols = [ensembl_to_symbol.get(gene, gene) for gene in selected_gene_names]\n",
    "\n",
    "# # Identify PAM50 genes in the selected genes\n",
    "# pam50_selected_genes = [gene for gene in gene_symbols if gene in pam50_set]\n",
    "\n",
    "# print(gene_symbols)\n",
    "# print(pam50_set)\n",
    "# print(pam50_set.intersection(set(gene_symbols)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_logreg_sbm_model = grid_search_logreg_sbm.best_estimator_['model']\n",
    "\n",
    "# print(f'Tuned Logistic Regression Model: {tuned_logreg_sbm_model}')\n",
    "\n",
    "# main_classifier = setup_pipeline(model=tuned_logreg_sbm_model, type='sbm').fit(X_train, y_train)\n",
    "# main_predictions = main_classifier.predict(X_test)\n",
    "\n",
    "# accuracy_main = accuracy_score(y_test, main_predictions)\n",
    "\n",
    "# print(f'Main Classifier Accuracy after Tuning: {accuracy_main:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "## Train ACC vs Test ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_acc_compare(main_classifier, X_train, y_train, y_test, main_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_gene_names = X.columns\n",
    "\n",
    "# estimator = grid_search_logreg_sbm.best_estimator_\n",
    "\n",
    "# selector = estimator.named_steps['feature_selection']\n",
    "# lr_model = estimator.named_steps['model']\n",
    "\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "# print(f\"Selected {len(selected_indices)} feature indices\")\n",
    "\n",
    "# selected_gene_names = [all_gene_names[i] for i in selected_indices]\n",
    "# print(f\"Selected {len(selected_gene_names)} genes\")\n",
    "\n",
    "# # Modify to look for symbols instead of Ensembl IDs with version numbers\n",
    "# selected_gene_names_modified = [gene.split('.')[0] for gene in selected_gene_names]\n",
    "# print(f\"Selected gene names after removing version numbers: {selected_gene_names_modified[:10]}\")\n",
    "\n",
    "# mg = mygene.MyGeneInfo()\n",
    "# gene_info = mg.querymany(\n",
    "#     selected_gene_names_modified,\n",
    "#     scopes='ensembl.gene',\n",
    "#     fields='symbol',\n",
    "#     species='human',\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# # Print first 5 entries of gene_info for verification\n",
    "# print(gene_info[:5])\n",
    "\n",
    "# ensembl_to_symbol = {}\n",
    "# for result in gene_info:\n",
    "#     ensembl_id = result['query']\n",
    "#     gene_symbol = result.get('symbol', ensembl_id)\n",
    "#     ensembl_to_symbol[ensembl_id] = gene_symbol\n",
    "\n",
    "# gene_symbols = [ensembl_to_symbol.get(gene, gene) for gene in selected_gene_names_modified]\n",
    "\n",
    "# class_names = ['Basal', 'Her2', 'LumA', 'LumB', 'Normal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {},
   "source": [
    "Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.LinearExplainer(lr_model, X_train[selected_gene_names])\n",
    "# shap_values = explainer.shap_values(X_test[selected_gene_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "Boxplot explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "# Classification Reports (LEGACY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "Classification Report - LR + LR Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_lr),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_lr),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "Classification Report - LR + RF Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_rf),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_rf),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130",
   "metadata": {},
   "source": [
    "Classification Report - LR + KBest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_kbest),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_kbest),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {},
   "source": [
    "### Classification Reports for RF Classifier with LR, RF and KBest as selection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "Classification Report - RF + LR Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_lr),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_lr),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {},
   "source": [
    "Classification Report - RF + RF Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_rf),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_rf),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {},
   "source": [
    "Classification Report - RF + KBest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_kbest),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_kbest),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "# REPORT (LEGACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Classification Report for Random Forest:\")\n",
    "# print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_rf))\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "# plt.title('Confusion Matrix for Random Forest Classifier')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Classification Report for Logistic Regression:\")\n",
    "# print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_lr))\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "# plt.title('Confusion Matrix for Logistic Regression Classifier')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Classification Report for XGBoost Classifier:\")\n",
    "# print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_xgb))\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "# plt.title('Confusion Matrix for XGBoost Classifier')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = range(len(encoder.classes_))\n",
    "# class_labels = encoder.classes_\n",
    "# number_of_classes = len(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba_rf = rf_classifier.predict_proba(X_test_selected)\n",
    "# y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "# for i, color in zip(range(number_of_classes), colors):\n",
    "#     labels_for_class = y_test_binarized[:, i]\n",
    "#     probs_for_class = y_pred_proba_rf[:, i]\n",
    "\n",
    "#     fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curves for Random Forest Classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba_lr = logreg_classifier.predict_proba(X_test_selected)\n",
    "# y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "# for i, color in zip(range(number_of_classes), colors):\n",
    "#     labels_for_class = y_test_binarized[:, i]\n",
    "#     probs_for_class = y_pred_proba_lr[:, i]\n",
    "\n",
    "#     fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curves for Logistic Regression Classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba_xgb = xgb_classifier.predict_proba(X_test_selected)\n",
    "# y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "# for i, color in zip(range(number_of_classes), colors):\n",
    "#     labels_for_class = y_test_binarized[:, i]\n",
    "#     probs_for_class = y_pred_proba_xgb[:, i]\n",
    "\n",
    "#     fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curves for XGBoost Classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154",
   "metadata": {},
   "source": [
    "## Train ACC vs Test ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_rf = rf_classifier.predict(X_train_selected)\n",
    "# train_f1_rf = f1_score(y_train, train_pred_rf, average='weighted')\n",
    "# test_f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "# print(f'Training F1 Score for Random Forest: {train_f1_rf:.6f}')\n",
    "# print(f'Test F1 Score for Random Forest: {test_f1_rf:.6f}')\n",
    "# print(f'F1 Score Difference for Random Forest: {train_f1_rf - test_f1_rf:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_lr = logreg_classifier.predict(X_train_selected)\n",
    "# train_f1_lr = f1_score(y_train, train_pred_lr, average='weighted')\n",
    "# test_f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "# print(f'Training F1 Score for Logistic Regression: {train_f1_lr:.6f}')\n",
    "# print(f'Test F1 Score for Logistic Regression: {test_f1_lr:.6f}')\n",
    "# print(f'F1 Score Difference for Logistic Regression: {train_f1_lr - test_f1_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_xgb = xgb_classifier.predict(X_train_selected)\n",
    "# train_f1_xgb = f1_score(y_train, train_pred_xgb, average='weighted')\n",
    "# test_f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "\n",
    "# print(f'Training F1 Score for XGBoost: {train_f1_xgb:.6f}')\n",
    "# print(f'Test F1 Score for XGBoost: {test_f1_xgb:.6f}')\n",
    "# print(f'F1 Score Difference for XGBoost: {train_f1_xgb - test_f1_xgb:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning (LEGACY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162",
   "metadata": {},
   "source": [
    "## GridsearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163",
   "metadata": {},
   "source": [
    "Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_usage = 6 # -1 = ALL Cores\n",
    "# scoring = \"f1_macro\"\n",
    "# select_k_list = [50, 75, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165",
   "metadata": {},
   "source": [
    "Define global pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_steps = [\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('filter', VarianceThreshold(threshold=0.1)),\n",
    "#     ('selector', SelectKBest(score_func=f_classif)),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iteration = 5000\n",
    "# random_state = 42\n",
    "\n",
    "# pipeline_lr = Pipeline(preprocessing_steps + [\n",
    "#     ('model', LogisticRegression(max_iter=max_iteration, random_state=random_state))\n",
    "# ])\n",
    "\n",
    "# param_grid_lr = {\n",
    "#     'selector__k': select_k_list,\n",
    "#     'model__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#     'model__solver': ['lbfgs', 'sag', 'saga'],\n",
    "#     'model__class_weight': ['balanced', None]\n",
    "# }\n",
    "\n",
    "# grid_search_lr = GridSearchCV(\n",
    "#     estimator=pipeline_lr,\n",
    "#     param_grid=param_grid_lr,\n",
    "#     scoring=scoring,\n",
    "#     cv=5,\n",
    "#     n_jobs=core_usage,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Best parameters found: {grid_search_lr.best_params_}')\n",
    "# print(f'Best {scoring} score: {grid_search_lr.best_score_:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169",
   "metadata": {},
   "source": [
    "## GridsearchCV Analysis Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest_model = SelectKBest(score_func=f_classif, k=grid_search_lr.best_params_['selector__k'])\n",
    "# X_train_selected = SelectKBest_model.fit_transform(X_train_filtered, y_train)\n",
    "# X_test_selected = SelectKBest_model.transform(X_test_filtered)\n",
    "\n",
    "# logreg_classifier = LogisticRegression(\n",
    "#     max_iter=max_iteration, \n",
    "#     random_state=random_state,\n",
    "#     C=grid_search_lr.best_params_['model__C'],\n",
    "#     solver=grid_search_lr.best_params_['model__solver'],\n",
    "#     class_weight=grid_search_lr.best_params_['model__class_weight']\n",
    "# )\n",
    "\n",
    "# logreg_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_lr = logreg_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# print(f'Logistic Regression Classifier Accuracy: {accuracy_lr:.6f}')\n",
    "\n",
    "# train_pred_lr = logreg_classifier.predict(X_train_selected)\n",
    "# train_f1_lr = f1_score(y_train, train_pred_lr, average='macro')\n",
    "# test_f1_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "\n",
    "# print(f'Training F1 Score for Logistic Regression: {train_f1_lr:.6f}')\n",
    "# print(f'Test F1 Score for Logistic Regression: {test_f1_lr:.6f}')\n",
    "# print(f'F1 Score Difference for Logistic Regression: {train_f1_lr - test_f1_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172",
   "metadata": {},
   "source": [
    "# SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_gene_names = list(df.columns)\n",
    "\n",
    "# best_model = grid_search_lr.best_estimator_\n",
    "\n",
    "# selector = best_model.named_steps['selector']\n",
    "# lr_model = best_model.named_steps['model']\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# selected_gene_names = [all_gene_names[i] for i in selected_indices]\n",
    "# print(f\"Selected {len(selected_gene_names)} genes\")\n",
    "\n",
    "# # Print first 10 selected gene names for verification\n",
    "# print(selected_gene_names[:10]) \n",
    "\n",
    "# selected_gene_names = [gene.split('.')[0] for gene in selected_gene_names]\n",
    "\n",
    "# # Print first 10 selected gene names after removing version numbers for verification\n",
    "# print(f\"Selected gene names after removing version numbers: {selected_gene_names[:10]}\")\n",
    "\n",
    "# # Gene symbol mapping using mygene\n",
    "# mg = mygene.MyGeneInfo()\n",
    "# gene_info = mg.querymany(\n",
    "#     selected_gene_names,\n",
    "#     scopes='ensembl.gene',\n",
    "#     fields='symbol',\n",
    "#     species='human',\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# # Print first 5 entries of gene_info for verification\n",
    "# print(gene_info[:5])\n",
    "\n",
    "# ensembl_to_symbol = {}\n",
    "# for result in gene_info:\n",
    "#     ensembl_id = result['query']\n",
    "#     gene_symbol = result.get('symbol', ensembl_id)\n",
    "#     ensembl_to_symbol[ensembl_id] = gene_symbol\n",
    "\n",
    "# gene_symbols = [ensembl_to_symbol.get(gene, gene) for gene in selected_gene_names]\n",
    "\n",
    "# class_names = ['Basal', 'Her2', 'LumA', 'LumB', 'Normal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175",
   "metadata": {},
   "source": [
    "Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.LinearExplainer(lr_model, X_train_selected)\n",
    "# shap_values = explainer.shap_values(X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177",
   "metadata": {},
   "source": [
    "Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 10))\n",
    "# shap.summary_plot(\n",
    "#     shap_values,\n",
    "#     X_test_selected,\n",
    "#     feature_names=gene_symbols,\n",
    "#     class_names=class_names,\n",
    "#     plot_type=\"bar\"\n",
    "# )\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179",
   "metadata": {},
   "source": [
    "Top Genes per Subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for class_idx, class_name in enumerate(class_names):\n",
    "#     # Calculate mean absolute SHAP value per gene for this class\n",
    "#     mean_abs_shap = np.abs(shap_values[class_idx]).mean(axis=0)\n",
    "    \n",
    "#     # Get top 10\n",
    "#     top_indices = np.argsort(mean_abs_shap)[-10:][::-1]\n",
    "    \n",
    "#     print(f\"\\n{class_name.upper()}:\")\n",
    "#     print(\"-\" * 70)\n",
    "#     for rank, idx in enumerate(top_indices, 1):\n",
    "#         gene_symbol = gene_symbols[idx]\n",
    "#         ensembl_id = selected_gene_names[idx]\n",
    "#         importance = mean_abs_shap[idx]\n",
    "#         print(f\"  {rank:2d}. {gene_symbol:15s} ({ensembl_id}) - Importance: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181",
   "metadata": {},
   "source": [
    "# Alternative selection method: Random Forest Selection (LEGACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df['Subtype']\n",
    "# X = df.drop(columns=['Subtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.log2(X + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186",
   "metadata": {},
   "source": [
    "Random Forest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_selector = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=6)\n",
    "\n",
    "# rf_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# importances = rf_selector.feature_importances_\n",
    "# top_n_genes = np.argsort(importances)[-50:]\n",
    "\n",
    "# X_train_selected = X_train_scaled[:, top_n_genes]\n",
    "# X_test_selected = X_test_scaled[:, top_n_genes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188",
   "metadata": {},
   "source": [
    "Logistic Regression Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_classifier = LogisticRegression(max_iter=1500, random_state=42, class_weight='balanced')\n",
    "\n",
    "# rfe_selector = RFE(estimator=lr_classifier, n_features_to_select=50, step=0.1, verbose=1)\n",
    "# rfe_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# selected_indices_lr = np.where(rfe_selector.support_)[0]\n",
    "# print(f\"Selected features for LR:\\n{selected_indices_lr}\\n\")\n",
    "\n",
    "# top_n_genes = selected_indices_lr\n",
    "\n",
    "# X_train_selected = X_train_scaled[:, top_n_genes]\n",
    "# X_test_selected = X_test_scaled[:, top_n_genes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190",
   "metadata": {},
   "source": [
    "List selected genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_ids = X.columns[top_n_genes]\n",
    "\n",
    "# gene_ids = [gene.split('.')[0] for gene in gene_ids]\n",
    "\n",
    "# mg = mygene.MyGeneInfo()\n",
    "# mygene_info = mg.querymany(\n",
    "#     list(gene_ids),\n",
    "#     scopes='ensembl.gene',\n",
    "#     fields='symbol',\n",
    "#     species='human',\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# print(\"All genes retrieved from mygene:\")\n",
    "# for gene in mygene_info:\n",
    "#     print(f\"Gene ID: {gene['query']}, Symbol: {gene['symbol'] if 'symbol' in gene else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_classifier = LogisticRegression(max_iter=1500, random_state=42, class_weight='balanced')\n",
    "# logreg_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_lr = logreg_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# print(f'Logistic Regression Classifier Accuracy with Top 100 RF Genes: {accuracy_lr:.6f}')\n",
    "\n",
    "# # F1 Score to check for overfitting\n",
    "# train_pred = logreg_classifier.predict(X_train_selected)\n",
    "# train_f1 = f1_score(y_train, train_pred, average='macro')\n",
    "# test_f1 = f1_score(y_test, y_pred_lr, average='macro')\n",
    "\n",
    "# print(f'Training F1 Score for Logistic Regression with Top 100 RF Genes: {train_f1:.6f}')\n",
    "# print(f'Test F1 Score for Logistic Regression with Top 100 RF Genes: {test_f1:.6f}')\n",
    "# print(f'F1 Score Difference for Logistic Regression with Top 100 RF Genes: {train_f1 - test_f1:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# random_forest_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_rf = random_forest_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# print(f'Random Forest Classifier Accuracy with Top 100 RF Genes: {accuracy_rf:.6f}')\n",
    "\n",
    "# # F1 Score to check for overfitting\n",
    "# train_pred_rf = random_forest_classifier.predict(X_train_selected)\n",
    "# train_f1_rf = f1_score(y_train, train_pred_rf, average='macro')\n",
    "# test_f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "\n",
    "# print(f'Training F1 Score for Random Forest with Top 100 RF Genes: {train_f1_rf:.6f}')\n",
    "# print(f'Test F1 Score for Random Forest with Top 100 RF Genes: {test_f1_rf:.6f}')\n",
    "# print(f'F1 Score Difference for Random Forest with Top 100 RF Genes: {train_f1_rf - test_f1_rf:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "\n",
    "# y = encoder.fit_transform(df['Subtype'])\n",
    "# X = df.drop(columns=['Subtype'])\n",
    "\n",
    "# X = np.log2(X + 1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# rf_selector = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=6)\n",
    "\n",
    "# rf_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# importances = rf_selector.feature_importances_\n",
    "# top_100_genes = np.argsort(importances)[-50:]\n",
    "\n",
    "# X_train_selected = X_train_scaled[:, top_100_genes]\n",
    "# X_test_selected = X_test_scaled[:, top_100_genes]\n",
    "\n",
    "# xgb_classifier = XGBClassifier(\n",
    "#     tree_method='auto',\n",
    "#     n_estimators=100,\n",
    "#     eval_metric='mlogloss', \n",
    "#     random_state=42,\n",
    "#     max_depth=6,\n",
    "# )\n",
    "# xgb_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_xgb = xgb_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "# print(f'XGBoost Classifier Accuracy with Top 100 RF Genes: {accuracy_xgb:.6f}')\n",
    "\n",
    "# # F1 Score to check for overfitting\n",
    "# train_pred_xgb = xgb_classifier.predict(X_train_selected)\n",
    "# train_f1_xgb = f1_score(y_train, train_pred_xgb, average='macro')\n",
    "# test_f1_xgb = f1_score(y_test, y_pred_xgb, average='macro')\n",
    "\n",
    "# print(f'Training F1 Score for XGBoost with Top 100 RF Genes: {train_f1_xgb:.6f}')\n",
    "# print(f'Test F1 Score for XGBoost with Top 100 RF Genes: {test_f1_xgb:.6f}')\n",
    "# print(f'F1 Score Difference for XGBoost with Top 100 RF Genes: {train_f1_xgb - test_f1_xgb:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
