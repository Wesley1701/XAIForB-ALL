{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Core (Always run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from itertools import cycle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\"\n",
    "dataset_file_name = \"dataset.pq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path_to_data + dataset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()\n",
    "\n",
    "print(f'Dataframe shape after transpose: {df.shape}')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Apply subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "excell_sheet_df = pd.read_excel('./assets/subtype_sheet.xlsx', sheet_name='RNA-Seq 1148')\n",
    "\n",
    "for sample_id in df.index:\n",
    "    print(f'Processing sample ID: {sample_id}')\n",
    "\n",
    "    if sample_id in excell_sheet_df['Sample ID'].values:\n",
    "        subtype = excell_sheet_df.loc[excell_sheet_df['Sample ID'] == sample_id, 'PAM50'].values[0]\n",
    "        print(f'Subtype found: {subtype}')\n",
    "        df.at[sample_id, 'Subtype'] = subtype\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Look for NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isna().sum().sum() > 0:\n",
    "    print(\"Dataframe contains missing values. Dropping missing values.\")\n",
    "    print(f'Number of missing values: {df.isna().sum().sum()}')\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(\"Missing values dropped.\")\n",
    "    print(f'Number of remaining missing values: {df.isna().sum().sum()}')\n",
    "else:\n",
    "    print(\"Dataframe does not contain missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Plot 1: Subtype distribution plot\n",
    "\n",
    "More info about the subtypes in this paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC6985186/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df.copy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=plot_df, x='Subtype', order=plot_df['Subtype'].value_counts().index)\n",
    "plt.title('Distribution of Subtypes')\n",
    "plt.xlabel('Subtype')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Plot 2: Scatter plot\n",
    "\n",
    "Observation: Contains a few outliers, not entirely sure what to do about them.\n",
    "\n",
    "https://stats.stackexchange.com/questions/533503/when-should-you-remove-outliers-entire-dataset-or-train-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_log_transformed = np.log1p(plot_df.select_dtypes(include=np.number))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(x_log_transformed)\n",
    "\n",
    "PCA_model = PCA(n_components=2)\n",
    "pca_result = PCA_model.fit_transform(df_scaled)\n",
    "plot_df['PCA1'] = pca_result[:, 0]\n",
    "plot_df['PCA2'] = pca_result[:, 1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=plot_df, x='PCA1', y='PCA2', hue='Subtype', palette='Set2')\n",
    "plt.title('PCA Scatter Plot Colored by Subtype')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend(title='Subtype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Plot 2.1: Scatter plot with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out outliers based on PCA1 and PCA2\n",
    "filtered_plot_df = plot_df[plot_df['PCA1'] < 2000]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_plot_df, x='PCA1', y='PCA2', hue='Subtype', palette='Set2')\n",
    "plt.title('PCA Scatter Plot with PCA1 < 2000 Colored by Subtype')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend(title='Subtype')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(df['Subtype'])\n",
    "X = df.drop(columns=['Subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Normalization - log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log2(X + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_filter = VarianceThreshold(threshold=0.1)\n",
    "X_train_filtered = variance_filter.fit_transform(X_train)\n",
    "X_test_filtered = variance_filter.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectKBest_model = SelectKBest(score_func=f_classif, k=50)\n",
    "X_train_selected = SelectKBest_model.fit_transform(X_train_filtered, y_train)\n",
    "X_test_selected = SelectKBest_model.transform(X_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_rf = rf_classifier.predict(X_test_selected)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Random Forest Classifier Accuracy: {accuracy_rf:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_classifier = LogisticRegression(max_iter=1500, random_state=42)\n",
    "logreg_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_lr = logreg_classifier.predict(X_test_selected)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f'Logistic Regression Classifier Accuracy: {accuracy_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "XGBoost\n",
    "\n",
    "Parameters for XGBClassifier: https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(\n",
    "    tree_method='auto',\n",
    "    n_estimators=100,\n",
    "    eval_metric='mlogloss', \n",
    "    random_state=42,\n",
    "    max_depth=6,\n",
    ")\n",
    "xgb_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_classifier.predict(X_test_selected)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'XGBoost Classifier Accuracy: {accuracy_xgb:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# Training Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for Random Forest:\")\n",
    "print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_rf))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title('Confusion Matrix for Random Forest Classifier')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for Logistic Regression:\")\n",
    "print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_lr))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title('Confusion Matrix for Logistic Regression Classifier')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for XGBoost Classifier:\")\n",
    "print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_xgb))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title('Confusion Matrix for XGBoost Classifier')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = range(len(encoder.classes_))\n",
    "class_labels = encoder.classes_\n",
    "number_of_classes = len(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_rf = rf_classifier.predict_proba(X_test_selected)\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "for i, color in zip(range(number_of_classes), colors):\n",
    "    labels_for_class = y_test_binarized[:, i]\n",
    "    probs_for_class = y_pred_proba_rf[:, i]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Random Forest Classifier')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_lr = logreg_classifier.predict_proba(X_test_selected)\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "for i, color in zip(range(number_of_classes), colors):\n",
    "    labels_for_class = y_test_binarized[:, i]\n",
    "    probs_for_class = y_pred_proba_lr[:, i]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Logistic Regression Classifier')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_xgb = xgb_classifier.predict_proba(X_test_selected)\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "for i, color in zip(range(number_of_classes), colors):\n",
    "    labels_for_class = y_test_binarized[:, i]\n",
    "    probs_for_class = y_pred_proba_xgb[:, i]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for XGBoost Classifier')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Train ACC vs Test ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_rf = rf_classifier.predict(X_train_selected)\n",
    "train_f1_rf = f1_score(y_train, train_pred_rf, average='weighted')\n",
    "test_f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "print(f'Training F1 Score for Random Forest: {train_f1_rf:.6f}')\n",
    "print(f'Test F1 Score for Random Forest: {test_f1_rf:.6f}')\n",
    "print(f'F1 Score Difference for Random Forest: {train_f1_rf - test_f1_rf:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_lr = logreg_classifier.predict(X_train_selected)\n",
    "train_f1_lr = f1_score(y_train, train_pred_lr, average='weighted')\n",
    "test_f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "print(f'Training F1 Score for Logistic Regression: {train_f1_lr:.6f}')\n",
    "print(f'Test F1 Score for Logistic Regression: {test_f1_lr:.6f}')\n",
    "print(f'F1 Score Difference for Logistic Regression: {train_f1_lr - test_f1_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_xgb = xgb_classifier.predict(X_train_selected)\n",
    "train_f1_xgb = f1_score(y_train, train_pred_xgb, average='weighted')\n",
    "test_f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "\n",
    "print(f'Training F1 Score for XGBoost: {train_f1_xgb:.6f}')\n",
    "print(f'Test F1 Score for XGBoost: {test_f1_xgb:.6f}')\n",
    "print(f'F1 Score Difference for XGBoost: {train_f1_xgb - test_f1_xgb:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
