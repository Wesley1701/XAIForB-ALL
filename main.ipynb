{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Core (Always run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import mygene\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from itertools import cycle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold, RFE, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\"\n",
    "dataset_file_name = \"dataset.pq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path_to_data + dataset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()\n",
    "\n",
    "print(f'Dataframe shape after transpose: {df.shape}')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Apply subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "excell_sheet_df = pd.read_excel('./assets/subtype_sheet.xlsx', sheet_name='RNA-Seq 1148')\n",
    "\n",
    "for sample_id in df.index:\n",
    "    print(f'Processing sample ID: {sample_id}')\n",
    "\n",
    "    if sample_id in excell_sheet_df['Sample ID'].values:\n",
    "        subtype = excell_sheet_df.loc[excell_sheet_df['Sample ID'] == sample_id, 'PAM50'].values[0]\n",
    "        print(f'Subtype found: {subtype}')\n",
    "        df.at[sample_id, 'Subtype'] = subtype\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Look for NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isna().sum().sum() > 0:\n",
    "    print(\"Dataframe contains missing values. Dropping missing values.\")\n",
    "    print(f'Number of missing values: {df.isna().sum().sum()}')\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(\"Missing values dropped.\")\n",
    "    print(f'Number of remaining missing values: {df.isna().sum().sum()}')\n",
    "else:\n",
    "    print(\"Dataframe does not contain missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Plot 1: Subtype distribution plot\n",
    "\n",
    "More info about the subtypes in this paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC6985186/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df.copy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=plot_df, x='Subtype', order=plot_df['Subtype'].value_counts().index)\n",
    "plt.title('Distribution of Subtypes')\n",
    "plt.xlabel('Subtype')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Plot 2: Scatter plot\n",
    "\n",
    "Observation: Contains a few outliers, not entirely sure what to do about them.\n",
    "\n",
    "https://stats.stackexchange.com/questions/533503/when-should-you-remove-outliers-entire-dataset-or-train-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_log_transformed = np.log1p(plot_df.select_dtypes(include=np.number))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(x_log_transformed)\n",
    "\n",
    "PCA_model = PCA(n_components=2)\n",
    "pca_result = PCA_model.fit_transform(df_scaled)\n",
    "plot_df['PCA1'] = pca_result[:, 0]\n",
    "plot_df['PCA2'] = pca_result[:, 1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=plot_df, x='PCA1', y='PCA2', hue='Subtype', palette='Set2')\n",
    "plt.title('PCA Scatter Plot Colored by Subtype')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend(title='Subtype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Plot 2.1: Scatter plot with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out outliers based on PCA1 and PCA2\n",
    "filtered_plot_df = plot_df[plot_df['PCA1'] < 2000]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_plot_df, x='PCA1', y='PCA2', hue='Subtype', palette='Set2')\n",
    "plt.title('PCA Scatter Plot with PCA1 < 2000 Colored by Subtype')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend(title='Subtype')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pipeline(model, type: str, settings: dict = {}) -> Pipeline:\n",
    "    \"\"\"Returns pipeline based on model and type of feature selection. Feature selection types: rfe, sbm, skb\"\"\"\n",
    "\n",
    "    base_list = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('variance_threshold', VarianceThreshold(threshold=0.1))\n",
    "    ]\n",
    "\n",
    "    if type == 'rfe':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', RFE(estimator=LogisticRegression(max_iter=1500, random_state=42, class_weight='balanced'), n_features_to_select=50, step=0.1)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    elif type == 'sbm':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', SelectFromModel(estimator=RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'), max_features=50)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    elif type == 'skb':\n",
    "        return Pipeline(base_list + [\n",
    "            ('feature_selection', SelectKBest(score_func=f_classif, k=50)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature selection type. Choose from 'lr', 'rf', or 'kbest'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(df['Subtype'])\n",
    "X = df.drop(columns=['Subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Normalization - log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log2(X + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Training Logistic Regression using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Logistic Regression - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_classifier_rfe = setup_pipeline(model=LogisticRegression(max_iter=1500, random_state=42), type='rfe').fit(X_train, y_train)\n",
    "logreg_predictions_rfe = logreg_classifier_rfe.predict(X_test)\n",
    "\n",
    "accuracy_logreg_rfe = accuracy_score(y_test, logreg_predictions_rfe)\n",
    "\n",
    "print(f'Logistic Regression with RFE Feature Selection Accuracy: {accuracy_logreg_rfe:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Logistic Regression - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_classifier_sbm = setup_pipeline(model=LogisticRegression(max_iter=1500, random_state=42), type='sbm').fit(X_train, y_train)\n",
    "logreg_predictions_sbm = logreg_classifier_sbm.predict(X_test)\n",
    "\n",
    "accuracy_logreg_sbm = accuracy_score(y_test, logreg_predictions_sbm)\n",
    "\n",
    "print(f'Logistic Regression with SBM Feature Selection Accuracy: {accuracy_logreg_sbm:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Logistic Regression - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_classifier_kbest = setup_pipeline(model=LogisticRegression(max_iter=1500, random_state=42), type='skb').fit(X_train, y_train)\n",
    "logreg_predictions_kbest = logreg_classifier_kbest.predict(X_test)\n",
    "\n",
    "accuracy_logreg_kbest = accuracy_score(y_test, logreg_predictions_kbest)\n",
    "\n",
    "print(f'Logistic Regression with KBest Feature Selection Accuracy: {accuracy_logreg_kbest:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## Training Random Forest using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Random Forest - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_rfe = setup_pipeline(model=RandomForestClassifier(n_estimators=100, random_state=42), type='rfe').fit(X_train, y_train)\n",
    "rf_predictions_rfe = rf_classifier_rfe.predict(X_test)\n",
    "\n",
    "accuracy_rf_rfe = accuracy_score(y_test, rf_predictions_rfe)\n",
    "\n",
    "print(f'Random Forest with RFE Feature Selection Accuracy: {accuracy_rf_rfe:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Random Forest - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_sbm = setup_pipeline(model=RandomForestClassifier(n_estimators=100, random_state=42), type='sbm').fit(X_train, y_train)\n",
    "rf_predictions_sbm = rf_classifier_sbm.predict(X_test)\n",
    "\n",
    "accuracy_rf_sbm = accuracy_score(y_test, rf_predictions_sbm)\n",
    "\n",
    "print(f'Random Forest with SBM Feature Selection Accuracy: {accuracy_rf_sbm:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Random Forest - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_kbest = setup_pipeline(model=RandomForestClassifier(n_estimators=100, random_state=42), type='skb').fit(X_train, y_train)\n",
    "rf_predictions_kbest = rf_classifier_kbest.predict(X_test)\n",
    "\n",
    "accuracy_rf_kbest = accuracy_score(y_test, rf_predictions_kbest)\n",
    "\n",
    "print(f'Random Forest with KBest Feature Selection Accuracy: {accuracy_rf_kbest:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Training XGBoost using LR, RF and KBest for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "XGBoost - RFE(LogisticRegression) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_rfe = setup_pipeline(model=XGBClassifier(eval_metric='mlogloss', random_state=42), type='rfe').fit(X_train, y_train)\n",
    "xgb_predictions_rfe = xgb_classifier_rfe.predict(X_test)\n",
    "\n",
    "accuracy_xgb_rfe = accuracy_score(y_test, xgb_predictions_rfe)\n",
    "\n",
    "print(f'XGBoost with RFE Feature Selection Accuracy: {accuracy_xgb_rfe:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "XGBoost - SelectBestModel(RandomForest) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_sbm = setup_pipeline(model=XGBClassifier(eval_metric='mlogloss', random_state=42), type='sbm').fit(X_train, y_train)\n",
    "xgb_predictions_sbm = xgb_classifier_sbm.predict(X_test)\n",
    "\n",
    "accuracy_xgb_sbm = accuracy_score(y_test, xgb_predictions_sbm)\n",
    "\n",
    "print(f'XGBoost with SBM Feature Selection Accuracy: {accuracy_xgb_sbm:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "XGBoost - SelectKBest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_skbest = setup_pipeline(model=XGBClassifier(eval_metric='mlogloss', random_state=42), type='skb').fit(X_train, y_train)\n",
    "xgb_predictions_kbest = xgb_classifier_skbest.predict(X_test)\n",
    "\n",
    "accuracy_xgb_kbest = accuracy_score(y_test, xgb_predictions_kbest)\n",
    "\n",
    "print(f'XGBoost with SKB Feature Selection Accuracy: {accuracy_xgb_kbest:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "# TRAINING LEGACY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard_scaler = StandardScaler()\n",
    "# X_train_scaled = standard_scaler.fit_transform(X_train)\n",
    "# X_test_scaled = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance_filter = VarianceThreshold(threshold=0.1)\n",
    "# X_train_filtered = variance_filter.fit_transform(X_train_scaled)\n",
    "# X_test_filtered = variance_filter.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Feature selection (SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest_model = SelectKBest(score_func=f_classif, k=50)\n",
    "# X_train_selected = SelectKBest_model.fit_transform(X_train_filtered, y_train)\n",
    "# X_test_selected = SelectKBest_model.transform(X_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_rf = rf_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# print(f'Random Forest Classifier Accuracy: {accuracy_rf:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_classifier = LogisticRegression(max_iter=1500, random_state=42)\n",
    "# logreg_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_lr = logreg_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# print(f'Logistic Regression Classifier Accuracy: {accuracy_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "XGBoost\n",
    "\n",
    "Parameters for XGBClassifier: https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_classifier = XGBClassifier(\n",
    "#     tree_method='auto',\n",
    "#     n_estimators=100,\n",
    "#     eval_metric='mlogloss', \n",
    "#     random_state=42,\n",
    "#     max_depth=6,\n",
    "# )\n",
    "# xgb_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_xgb = xgb_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "# print(f'XGBoost Classifier Accuracy: {accuracy_xgb:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "# Training Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_report(y_true, y_pred):\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred\n",
    "    )\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "def generate_confusion_matrix(y_true, y_pred, class_names, title_additional=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    if title_additional:\n",
    "        plt.title(f'Confusion Matrix - {title_additional}')\n",
    "    else:\n",
    "        plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def plot_cm_on_ax(ax, y_true, y_pred, class_names, title=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, \n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='Blues', \n",
    "                xticklabels=class_names, \n",
    "                yticklabels=class_names,\n",
    "                ax=ax,          # <<< Plots on the provided subplot\n",
    "                cbar=True)      # You can set this to False if you want\n",
    "    \n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title(title, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### Classification Reports - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = ['Model (LR-RFE)', 'Model (RF-Select)', 'Model (KBest)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_lr = [logreg_predictions_rfe, logreg_predictions_sbm, logreg_predictions_kbest]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 6))\n",
    "\n",
    "for ax, y_pred, title in zip(axes, all_preds_lr, all_titles):\n",
    "    plot_cm_on_ax(ax, \n",
    "                  y_true=y_test, \n",
    "                  y_pred=y_pred, \n",
    "                  class_names=encoder.classes_, \n",
    "                  title=title\n",
    "                )\n",
    "\n",
    "fig.suptitle('Logistic Regression Model - Feature Selection', fontsize=20, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "### Classification Reports - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_rf = [rf_predictions_rfe, rf_predictions_sbm, rf_predictions_kbest]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 6))\n",
    "\n",
    "for ax, y_pred, title in zip(axes, all_preds_rf, all_titles):\n",
    "    plot_cm_on_ax(ax, \n",
    "                  y_true=y_test, \n",
    "                  y_pred=y_pred, \n",
    "                  class_names=encoder.classes_, \n",
    "                  title=title\n",
    "                )\n",
    "\n",
    "fig.suptitle('Random Forest Model - Feature Selection', fontsize=20, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "### Classification Reports - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_xgb = [xgb_predictions_rfe, xgb_predictions_sbm, xgb_predictions_kbest]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 6))\n",
    "for ax, y_pred, title in zip(axes, all_preds_xgb, all_titles):\n",
    "    plot_cm_on_ax(ax, \n",
    "                  y_true=y_test, \n",
    "                  y_pred=y_pred, \n",
    "                  class_names=encoder.classes_, \n",
    "                  title=title\n",
    "                )\n",
    "\n",
    "fig.suptitle('XGBoost Model - Feature Selection', fontsize=20, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## Train ACC vs Test ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_acc_compare(model, X_train, y_train, y_test, y_pred):\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_f1 = f1_score(y_train, train_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f'Model name: {model.named_steps[\"model\"].__class__.__name__}')\n",
    "    print(f'Feature Selection Method: {model.named_steps[\"feature_selection\"].__class__.__name__}')\n",
    "    print('---')\n",
    "    print(f'Accuracy Score: {acc_score:.4f}')\n",
    "    print('---')\n",
    "    print(f'Training F1 Score: {train_f1:.4f}')\n",
    "    print(f'Testing F1 Score: {test_f1:.4f}')\n",
    "    print(f'F1 Score Difference (Train - Test): {train_f1 - test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_acc_compare(logreg_classifier_rfe, X_train, y_train, y_test, logreg_predictions_rfe)\n",
    "print(\"\\n\")\n",
    "train_test_acc_compare(logreg_classifier_sbm, X_train, y_train, y_test, logreg_predictions_sbm)\n",
    "print(\"\\n\")\n",
    "train_test_acc_compare(logreg_classifier_kbest, X_train, y_train, y_test, logreg_predictions_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_acc_compare(rf_classifier_rfe, X_train, y_train, y_test, rf_predictions_rfe)\n",
    "print(\"\\n\")\n",
    "train_test_acc_compare(rf_classifier_sbm, X_train, y_train, y_test, rf_predictions_sbm)\n",
    "print(\"\\n\")\n",
    "train_test_acc_compare(rf_classifier_kbest, X_train, y_train, y_test, rf_predictions_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_acc_compare(xgb_classifier_rfe, X_train, y_train, y_test, xgb_predictions_rfe)\n",
    "print(\"\\n\")\n",
    "train_test_acc_compare(xgb_classifier_sbm, X_train, y_train, y_test, xgb_predictions_sbm)\n",
    "print(\"\\n\")\n",
    "train_test_acc_compare(xgb_classifier_skbest, X_train, y_train, y_test, xgb_predictions_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "## Tuning process\n",
    "\n",
    "Possible scoring values are: 'accuracy', 'f1_macro', 'f1_weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1_macro' # metric for evaluation\n",
    "n_features = [50, 75, 100]\n",
    "n_jobs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_sbm_pipeline = setup_pipeline(model=LogisticRegression(max_iter=7500, random_state=42), type='sbm')\n",
    "\n",
    "param_grid_logreg_sbm = [\n",
    "    {\n",
    "        'feature_selection__max_features': n_features,\n",
    "        'model__penalty': ['l1'],\n",
    "        'model__solver': ['saga'],\n",
    "        'model__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'model__class_weight': ['balanced']\n",
    "    },\n",
    "    {\n",
    "        'feature_selection__max_features': n_features,\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs', 'newton-cg', 'newton-cholesky'],\n",
    "        'model__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'model__class_weight': ['balanced']\n",
    "    }\n",
    "]\n",
    "grid_search_logreg_sbm = GridSearchCV(estimator=logreg_sbm_pipeline, param_grid=param_grid_logreg_sbm, scoring=scoring, cv=5, n_jobs=n_jobs, verbose=2)\n",
    "\n",
    "grid_search_logreg_sbm.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters for Logistic Regression with SBM: {grid_search_logreg_sbm.best_params_}')\n",
    "print(f'Best {scoring} score for Logistic Regression with SBM: {grid_search_logreg_sbm.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_logreg_sbm_model = grid_search_logreg_sbm.best_estimator_['model']\n",
    "\n",
    "print(f'Tuned Logistic Regression Model: {tuned_logreg_sbm_model}')\n",
    "\n",
    "main_classifier = setup_pipeline(model=tuned_logreg_sbm_model, type='sbm').fit(X_train, y_train)\n",
    "main_predictions = main_classifier.predict(X_test)\n",
    "\n",
    "accuracy_main = accuracy_score(y_test, main_predictions)\n",
    "\n",
    "print(f'Main Classifier Accuracy after Tuning: {accuracy_main:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "## Train ACC vs Test ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_acc_compare(main_classifier, X_train, y_train, y_test, main_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "# Classification Reports (LEGACY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "Classification Report - LR + LR Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_lr),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_lr),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "Classification Report - LR + RF Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_rf),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_rf),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "Classification Report - LR + KBest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_kbest),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(logreg_predictions_kbest),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### Classification Reports for RF Classifier with LR, RF and KBest as selection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "Classification Report - RF + LR Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_lr),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_lr),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "Classification Report - RF + RF Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_rf),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_rf),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "Classification Report - RF + KBest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_classification_report(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_kbest),\n",
    "# )\n",
    "\n",
    "# generate_confusion_matrix(\n",
    "#     encoder.inverse_transform(y_test),\n",
    "#     encoder.inverse_transform(rf_predictions_kbest),\n",
    "#     class_names=encoder.classes_\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "# REPORT (LEGACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Classification Report for Random Forest:\")\n",
    "# print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_rf))\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "# plt.title('Confusion Matrix for Random Forest Classifier')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Classification Report for Logistic Regression:\")\n",
    "# print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_lr))\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "# plt.title('Confusion Matrix for Logistic Regression Classifier')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Classification Report for XGBoost Classifier:\")\n",
    "# print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(encoder.inverse_transform(y_test), encoder.inverse_transform(y_pred_xgb))\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "# plt.title('Confusion Matrix for XGBoost Classifier')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = range(len(encoder.classes_))\n",
    "# class_labels = encoder.classes_\n",
    "# number_of_classes = len(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba_rf = rf_classifier.predict_proba(X_test_selected)\n",
    "# y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "# for i, color in zip(range(number_of_classes), colors):\n",
    "#     labels_for_class = y_test_binarized[:, i]\n",
    "#     probs_for_class = y_pred_proba_rf[:, i]\n",
    "\n",
    "#     fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curves for Random Forest Classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba_lr = logreg_classifier.predict_proba(X_test_selected)\n",
    "# y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "# for i, color in zip(range(number_of_classes), colors):\n",
    "#     labels_for_class = y_test_binarized[:, i]\n",
    "#     probs_for_class = y_pred_proba_lr[:, i]\n",
    "\n",
    "#     fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curves for Logistic Regression Classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba_xgb = xgb_classifier.predict_proba(X_test_selected)\n",
    "# y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "\n",
    "# for i, color in zip(range(number_of_classes), colors):\n",
    "#     labels_for_class = y_test_binarized[:, i]\n",
    "#     probs_for_class = y_pred_proba_xgb[:, i]\n",
    "\n",
    "#     fpr, tpr, _ = roc_curve(labels_for_class, probs_for_class)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     plt.plot(fpr, tpr, color=color, lw=2, label=f'ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.50)')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curves for XGBoost Classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "## Train ACC vs Test ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_rf = rf_classifier.predict(X_train_selected)\n",
    "# train_f1_rf = f1_score(y_train, train_pred_rf, average='weighted')\n",
    "# test_f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "# print(f'Training F1 Score for Random Forest: {train_f1_rf:.6f}')\n",
    "# print(f'Test F1 Score for Random Forest: {test_f1_rf:.6f}')\n",
    "# print(f'F1 Score Difference for Random Forest: {train_f1_rf - test_f1_rf:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_lr = logreg_classifier.predict(X_train_selected)\n",
    "# train_f1_lr = f1_score(y_train, train_pred_lr, average='weighted')\n",
    "# test_f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "# print(f'Training F1 Score for Logistic Regression: {train_f1_lr:.6f}')\n",
    "# print(f'Test F1 Score for Logistic Regression: {test_f1_lr:.6f}')\n",
    "# print(f'F1 Score Difference for Logistic Regression: {train_f1_lr - test_f1_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_xgb = xgb_classifier.predict(X_train_selected)\n",
    "# train_f1_xgb = f1_score(y_train, train_pred_xgb, average='weighted')\n",
    "# test_f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "\n",
    "# print(f'Training F1 Score for XGBoost: {train_f1_xgb:.6f}')\n",
    "# print(f'Test F1 Score for XGBoost: {test_f1_xgb:.6f}')\n",
    "# print(f'F1 Score Difference for XGBoost: {train_f1_xgb - test_f1_xgb:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning (LEGACY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "## GridsearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134",
   "metadata": {},
   "source": [
    "Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_usage = 6 # -1 = ALL Cores\n",
    "# scoring = \"f1_macro\"\n",
    "# select_k_list = [50, 75, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136",
   "metadata": {},
   "source": [
    "Define global pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_steps = [\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('filter', VarianceThreshold(threshold=0.1)),\n",
    "#     ('selector', SelectKBest(score_func=f_classif)),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iteration = 5000\n",
    "# random_state = 42\n",
    "\n",
    "# pipeline_lr = Pipeline(preprocessing_steps + [\n",
    "#     ('model', LogisticRegression(max_iter=max_iteration, random_state=random_state))\n",
    "# ])\n",
    "\n",
    "# param_grid_lr = {\n",
    "#     'selector__k': select_k_list,\n",
    "#     'model__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#     'model__solver': ['lbfgs', 'sag', 'saga'],\n",
    "#     'model__class_weight': ['balanced', None]\n",
    "# }\n",
    "\n",
    "# grid_search_lr = GridSearchCV(\n",
    "#     estimator=pipeline_lr,\n",
    "#     param_grid=param_grid_lr,\n",
    "#     scoring=scoring,\n",
    "#     cv=5,\n",
    "#     n_jobs=core_usage,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Best parameters found: {grid_search_lr.best_params_}')\n",
    "# print(f'Best {scoring} score: {grid_search_lr.best_score_:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140",
   "metadata": {},
   "source": [
    "## GridsearchCV Analysis Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141",
   "metadata": {},
   "source": [
    "Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest_model = SelectKBest(score_func=f_classif, k=grid_search_lr.best_params_['selector__k'])\n",
    "# X_train_selected = SelectKBest_model.fit_transform(X_train_filtered, y_train)\n",
    "# X_test_selected = SelectKBest_model.transform(X_test_filtered)\n",
    "\n",
    "# logreg_classifier = LogisticRegression(\n",
    "#     max_iter=max_iteration, \n",
    "#     random_state=random_state,\n",
    "#     C=grid_search_lr.best_params_['model__C'],\n",
    "#     solver=grid_search_lr.best_params_['model__solver'],\n",
    "#     class_weight=grid_search_lr.best_params_['model__class_weight']\n",
    "# )\n",
    "\n",
    "# logreg_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_lr = logreg_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# print(f'Logistic Regression Classifier Accuracy: {accuracy_lr:.6f}')\n",
    "\n",
    "# train_pred_lr = logreg_classifier.predict(X_train_selected)\n",
    "# train_f1_lr = f1_score(y_train, train_pred_lr, average='macro')\n",
    "# test_f1_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "\n",
    "# print(f'Training F1 Score for Logistic Regression: {train_f1_lr:.6f}')\n",
    "# print(f'Test F1 Score for Logistic Regression: {test_f1_lr:.6f}')\n",
    "# print(f'F1 Score Difference for Logistic Regression: {train_f1_lr - test_f1_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143",
   "metadata": {},
   "source": [
    "# SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_gene_names = list(df.columns)\n",
    "\n",
    "# best_model = grid_search_lr.best_estimator_\n",
    "\n",
    "# selector = best_model.named_steps['selector']\n",
    "# lr_model = best_model.named_steps['model']\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# selected_gene_names = [all_gene_names[i] for i in selected_indices]\n",
    "# print(f\"Selected {len(selected_gene_names)} genes\")\n",
    "\n",
    "# # Print first 10 selected gene names for verification\n",
    "# print(selected_gene_names[:10]) \n",
    "\n",
    "# selected_gene_names = [gene.split('.')[0] for gene in selected_gene_names]\n",
    "\n",
    "# # Print first 10 selected gene names after removing version numbers for verification\n",
    "# print(f\"Selected gene names after removing version numbers: {selected_gene_names[:10]}\")\n",
    "\n",
    "# # Gene symbol mapping using mygene\n",
    "# mg = mygene.MyGeneInfo()\n",
    "# gene_info = mg.querymany(\n",
    "#     selected_gene_names,\n",
    "#     scopes='ensembl.gene',\n",
    "#     fields='symbol',\n",
    "#     species='human',\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# # Print first 5 entries of gene_info for verification\n",
    "# print(gene_info[:5])\n",
    "\n",
    "# ensembl_to_symbol = {}\n",
    "# for result in gene_info:\n",
    "#     ensembl_id = result['query']\n",
    "#     gene_symbol = result.get('symbol', ensembl_id)\n",
    "#     ensembl_to_symbol[ensembl_id] = gene_symbol\n",
    "\n",
    "# gene_symbols = [ensembl_to_symbol.get(gene, gene) for gene in selected_gene_names]\n",
    "\n",
    "# class_names = ['Basal', 'Her2', 'LumA', 'LumB', 'Normal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {},
   "source": [
    "Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.LinearExplainer(lr_model, X_train_selected)\n",
    "# shap_values = explainer.shap_values(X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148",
   "metadata": {},
   "source": [
    "Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 10))\n",
    "# shap.summary_plot(\n",
    "#     shap_values,\n",
    "#     X_test_selected,\n",
    "#     feature_names=gene_symbols,\n",
    "#     class_names=class_names,\n",
    "#     plot_type=\"bar\"\n",
    "# )\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150",
   "metadata": {},
   "source": [
    "Top Genes per Subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for class_idx, class_name in enumerate(class_names):\n",
    "#     # Calculate mean absolute SHAP value per gene for this class\n",
    "#     mean_abs_shap = np.abs(shap_values[class_idx]).mean(axis=0)\n",
    "    \n",
    "#     # Get top 10\n",
    "#     top_indices = np.argsort(mean_abs_shap)[-10:][::-1]\n",
    "    \n",
    "#     print(f\"\\n{class_name.upper()}:\")\n",
    "#     print(\"-\" * 70)\n",
    "#     for rank, idx in enumerate(top_indices, 1):\n",
    "#         gene_symbol = gene_symbols[idx]\n",
    "#         ensembl_id = selected_gene_names[idx]\n",
    "#         importance = mean_abs_shap[idx]\n",
    "#         print(f\"  {rank:2d}. {gene_symbol:15s} ({ensembl_id}) - Importance: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152",
   "metadata": {},
   "source": [
    "# Alternative selection method: Random Forest Selection (LEGACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df['Subtype']\n",
    "# X = df.drop(columns=['Subtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.log2(X + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157",
   "metadata": {},
   "source": [
    "Random Forest Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_selector = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=6)\n",
    "\n",
    "# rf_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# importances = rf_selector.feature_importances_\n",
    "# top_n_genes = np.argsort(importances)[-50:]\n",
    "\n",
    "# X_train_selected = X_train_scaled[:, top_n_genes]\n",
    "# X_test_selected = X_test_scaled[:, top_n_genes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159",
   "metadata": {},
   "source": [
    "Logistic Regression Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_classifier = LogisticRegression(max_iter=1500, random_state=42, class_weight='balanced')\n",
    "\n",
    "# rfe_selector = RFE(estimator=lr_classifier, n_features_to_select=50, step=0.1, verbose=1)\n",
    "# rfe_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# selected_indices_lr = np.where(rfe_selector.support_)[0]\n",
    "# print(f\"Selected features for LR:\\n{selected_indices_lr}\\n\")\n",
    "\n",
    "# top_n_genes = selected_indices_lr\n",
    "\n",
    "# X_train_selected = X_train_scaled[:, top_n_genes]\n",
    "# X_test_selected = X_test_scaled[:, top_n_genes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "List selected genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_ids = X.columns[top_n_genes]\n",
    "\n",
    "# gene_ids = [gene.split('.')[0] for gene in gene_ids]\n",
    "\n",
    "# mg = mygene.MyGeneInfo()\n",
    "# mygene_info = mg.querymany(\n",
    "#     list(gene_ids),\n",
    "#     scopes='ensembl.gene',\n",
    "#     fields='symbol',\n",
    "#     species='human',\n",
    "#     verbose=False\n",
    "# )\n",
    "\n",
    "# print(\"All genes retrieved from mygene:\")\n",
    "# for gene in mygene_info:\n",
    "#     print(f\"Gene ID: {gene['query']}, Symbol: {gene['symbol'] if 'symbol' in gene else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_classifier = LogisticRegression(max_iter=1500, random_state=42, class_weight='balanced')\n",
    "# logreg_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_lr = logreg_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# print(f'Logistic Regression Classifier Accuracy with Top 100 RF Genes: {accuracy_lr:.6f}')\n",
    "\n",
    "# # F1 Score to check for overfitting\n",
    "# train_pred = logreg_classifier.predict(X_train_selected)\n",
    "# train_f1 = f1_score(y_train, train_pred, average='macro')\n",
    "# test_f1 = f1_score(y_test, y_pred_lr, average='macro')\n",
    "\n",
    "# print(f'Training F1 Score for Logistic Regression with Top 100 RF Genes: {train_f1:.6f}')\n",
    "# print(f'Test F1 Score for Logistic Regression with Top 100 RF Genes: {test_f1:.6f}')\n",
    "# print(f'F1 Score Difference for Logistic Regression with Top 100 RF Genes: {train_f1 - test_f1:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# random_forest_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_rf = random_forest_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# print(f'Random Forest Classifier Accuracy with Top 100 RF Genes: {accuracy_rf:.6f}')\n",
    "\n",
    "# # F1 Score to check for overfitting\n",
    "# train_pred_rf = random_forest_classifier.predict(X_train_selected)\n",
    "# train_f1_rf = f1_score(y_train, train_pred_rf, average='macro')\n",
    "# test_f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "\n",
    "# print(f'Training F1 Score for Random Forest with Top 100 RF Genes: {train_f1_rf:.6f}')\n",
    "# print(f'Test F1 Score for Random Forest with Top 100 RF Genes: {test_f1_rf:.6f}')\n",
    "# print(f'F1 Score Difference for Random Forest with Top 100 RF Genes: {train_f1_rf - test_f1_rf:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "\n",
    "# y = encoder.fit_transform(df['Subtype'])\n",
    "# X = df.drop(columns=['Subtype'])\n",
    "\n",
    "# X = np.log2(X + 1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# rf_selector = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=6)\n",
    "\n",
    "# rf_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# importances = rf_selector.feature_importances_\n",
    "# top_100_genes = np.argsort(importances)[-50:]\n",
    "\n",
    "# X_train_selected = X_train_scaled[:, top_100_genes]\n",
    "# X_test_selected = X_test_scaled[:, top_100_genes]\n",
    "\n",
    "# xgb_classifier = XGBClassifier(\n",
    "#     tree_method='auto',\n",
    "#     n_estimators=100,\n",
    "#     eval_metric='mlogloss', \n",
    "#     random_state=42,\n",
    "#     max_depth=6,\n",
    "# )\n",
    "# xgb_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# y_pred_xgb = xgb_classifier.predict(X_test_selected)\n",
    "\n",
    "# accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "# print(f'XGBoost Classifier Accuracy with Top 100 RF Genes: {accuracy_xgb:.6f}')\n",
    "\n",
    "# # F1 Score to check for overfitting\n",
    "# train_pred_xgb = xgb_classifier.predict(X_train_selected)\n",
    "# train_f1_xgb = f1_score(y_train, train_pred_xgb, average='macro')\n",
    "# test_f1_xgb = f1_score(y_test, y_pred_xgb, average='macro')\n",
    "\n",
    "# print(f'Training F1 Score for XGBoost with Top 100 RF Genes: {train_f1_xgb:.6f}')\n",
    "# print(f'Test F1 Score for XGBoost with Top 100 RF Genes: {test_f1_xgb:.6f}')\n",
    "# print(f'F1 Score Difference for XGBoost with Top 100 RF Genes: {train_f1_xgb - test_f1_xgb:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
