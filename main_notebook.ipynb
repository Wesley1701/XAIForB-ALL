{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Classify B-ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "- After every kernel restart rerun \"Core\"\n",
    "- It's best to restart after you run a training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Core (Always run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import shap\n",
    "import optuna\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "path_to_data = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_all = pd.read_parquet(f\"{path_to_data}B_ALL.pq\")\n",
    "df_all = pd.read_parquet(f\"{path_to_data}ALL.pq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_all_length = len(df_b_all.columns.drop(['gene_name', 'gene_type']))\n",
    "all_length = len(df_all.columns.drop(['gene_name', 'gene_type']))\n",
    "\n",
    "total_length = b_all_length + all_length\n",
    "\n",
    "df_b_all_filtered = df_b_all[df_b_all['gene_type'] == 'protein_coding']\n",
    "df_all_filtered = df_all[df_all['gene_type'] == 'protein_coding']\n",
    "\n",
    "df_b_all_filtered = df_b_all_filtered.drop(['gene_name', 'gene_type'], axis=1)\n",
    "df_all_filtered = df_all_filtered.drop(['gene_name', 'gene_type'], axis=1)\n",
    "\n",
    "df_b_all_filtered = df_b_all_filtered.fillna(0).select_dtypes(include='number').T\n",
    "df_all_filtered = df_all_filtered.fillna(0).select_dtypes(include='number').T\n",
    "\n",
    "print(\"Filtered B-ALL length:\", len(df_b_all_filtered))\n",
    "print(\"Filtered ALL length:\", len(df_all_filtered))\n",
    "\n",
    "combined_df = pd.concat([df_b_all_filtered, df_all_filtered], axis=0)\n",
    "\n",
    "combined_df['condition'] = [1] * len(df_all_filtered) + [0] * len(df_b_all_filtered)\n",
    "\n",
    "if (len(df_b_all_filtered) + len(df_all_filtered)) != combined_df.shape[0]:\n",
    "    print(f\"Expected number of rows: {len(df_b_all_filtered) + len(df_all_filtered)}, Actual number of rows: {combined_df.shape[0]}\")\n",
    "    raise ValueError(\"The number of rows in the combined DataFrame does not match the sum of B-ALL and B-ALL Healthy lengths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "sample_genes = np.random.choice(combined_df.columns, size=1000, replace=False)\n",
    "sample_data = combined_df[sample_genes]\n",
    "\n",
    "# Flatten the data for plotting\n",
    "raw_values = sample_data.values.flatten()\n",
    "log2_values = np.log2(sample_data + 1).values.flatten()\n",
    "\n",
    "# Create side-by-side histograms\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Raw expression distribution\n",
    "ax1.hist(raw_values, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax1.set_xlabel('Raw Expression Values')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Before Log2 Transformation\\n(Right-skewed Distribution)')\n",
    "ax1.set_yscale('log')  # Use log scale for y-axis due to extreme skew\n",
    "\n",
    "# Log2 transformed distribution\n",
    "ax2.hist(log2_values, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "ax2.set_xlabel('Log2(Expression + 1)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('After Log2 Transformation\\n(More Normal Distribution)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('RNA-Seq Expression Distribution: Raw vs Log2 Transformed', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = combined_df.copy()\n",
    "\n",
    "expr_z = StandardScaler().fit_transform(expr)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "coords = pca.fit_transform(expr_z)\n",
    "\n",
    "pc_df = pd.DataFrame(coords, columns=['PC1', 'PC2'], index=expr.index)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.scatterplot(data=pc_df, x='PC1', y='PC2', s=8, alpha=0.6)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=['B-ALL', 'ALL'], y=[len(df_b_all_filtered), len(df_all_filtered)])\n",
    "plt.title('Number of Samples in B-ALL and ALL')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xlabel('Condition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = combined_df['condition']  # Use the 'condition' column as the target variable\n",
    "\n",
    "combined_df.drop(columns=['condition'], inplace=True)  # Drop the 'condition' column for normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Log2 Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_normalized = np.log2(combined_df + 1)  # Log2 transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_normalized.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    merged_df_normalized, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {x_train.shape}, Test set shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution before SMOTE (using original y)\n",
    "counts_before = pd.Series(y).value_counts().sort_index()\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=counts_before.index, y=counts_before.values, palette=\"pastel\")\n",
    "plt.xlabel(\"Class (B-ALL=0, ALL=1)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Distribution Before SMOTE\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42, sampling_strategy='auto', k_neighbors=5)\n",
    "\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_after = pd.Series(y_train).value_counts().sort_index()\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=counts_after.index, y=counts_after.values, palette=\"pastel\")\n",
    "plt.xlabel(\"Class (B-ALL=0, ALL=1)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Distribution After SMOTE\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"After SMOTE, training set shape: {x_train.shape}, Test set shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_results = {\"xgboost\": [], \"random_forest\": [], \"logistic_regression\": []}\n",
    "\n",
    "# Callback to record each trial's model type and its score.\n",
    "def record_trial_callback(study, trial):\n",
    "    classifier = trial.params.get(\"classifier\")\n",
    "    trial_results[classifier].append((trial.number, trial.value))\n",
    "\n",
    "def optimize_classifier(x, y, n_trials=20):\n",
    "    def objective(trial):\n",
    "        k = trial.suggest_int(\"k\", 20, 100)  # k is capped at half of features.\n",
    "        classifier_choice = trial.suggest_categorical(\"classifier\", [\"xgboost\", \"random_forest\", \"logistic_regression\"])\n",
    "    \n",
    "        if classifier_choice == \"xgboost\":\n",
    "            params = {\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "                \"tree_method\": \"hist\",\n",
    "                \"objective\": \"binary:logistic\",\n",
    "                \"eval_metric\": \"auc\",\n",
    "            }\n",
    "            model = xgb.XGBClassifier(**params, use_label_encoder=False, verbosity=0)\n",
    "        elif classifier_choice == \"random_forest\":\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators_rf\", 20, 150),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth_rf\", 3, 12),\n",
    "                \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            }\n",
    "            model = RandomForestClassifier(**params, random_state=42)\n",
    "        elif classifier_choice == \"logistic_regression\":\n",
    "            c_value = trial.suggest_float(\"C\", 1e-4, 1e2, log=True)\n",
    "            model = LogisticRegression(C=c_value, solver=\"liblinear\",\n",
    "                                       random_state=42, class_weight=\"balanced\", max_iter=1000)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported classifier selected.\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            (\"select_kbest\", SelectKBest(score_func=f_classif, k=k)),\n",
    "            (\"classifier\", model)\n",
    "        ])\n",
    "    \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        score = cross_val_score(pipeline, x, y, scoring=\"roc_auc\", cv=cv).mean()\n",
    "    \n",
    "        if np.isnan(score):\n",
    "            print(\"NaN score encountered, returning a low score.\")\n",
    "            return 0.0\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[record_trial_callback])\n",
    "    \n",
    "    print(\"Best parameters:\", study.best_params)\n",
    "    print(\"Best ROC-AUC:\", study.best_value)\n",
    "    return study\n",
    "\n",
    "# Run the optimization.\n",
    "study_result = optimize_classifier(x_train, y_train, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Apply Optuna result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = {}\n",
    "for clf in trial_results:\n",
    "    if trial_results[clf]:\n",
    "        best_trial = max(trial_results[clf], key=lambda t: t[1])\n",
    "        best_scores[clf] = best_trial[1]\n",
    "    else:\n",
    "        best_scores[clf] = 0\n",
    "\n",
    "models = list(best_scores.keys())\n",
    "scores = [best_scores[m] for m in models]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(models, scores, color=['blue', 'green', 'orange'])\n",
    "plt.ylabel(\"Best ROC-AUC\")\n",
    "plt.xlabel(\"Classifier\")\n",
    "plt.title(\"Best ROC-AUC per Classifier from Optuna Trials\")\n",
    "plt.ylim(0, 1)\n",
    "for bar, score in zip(bars, scores):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "if not os.path.exists(\"plots\"):\n",
    "    os.makedirs(\"plots\")\n",
    "\n",
    "plot_path = os.path.join(\"plots\", \"best_classifier_comparison.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of x_train after feature selection: {x_train.shape}\"\n",
    "      f\", Shape of y_test: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study_result.best_params\n",
    "\n",
    "# Create the SelectKBest object\n",
    "select_k_best = SelectKBest(score_func=f_classif, k=best_params[\"k\"])\n",
    "\n",
    "# Fit and transform the training data\n",
    "x_train_selected = select_k_best.fit_transform(x_train, y_train)\n",
    "\n",
    "# Get the selected feature names\n",
    "# Note: merged_df_normalized should be your original feature matrix before scaling\n",
    "selected_feature_indices = select_k_best.get_support(indices=True)\n",
    "selected_feature_names = merged_df_normalized.columns[selected_feature_indices].tolist()\n",
    "\n",
    "# Transform test data\n",
    "x_test_selected = select_k_best.transform(x_test)\n",
    "\n",
    "# Update your variables\n",
    "x_train = x_train_selected\n",
    "x_test = x_test_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    tree_method=\"hist\",\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    use_label_encoder=False,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_proba = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC-AUC on test set: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Statistics and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix please\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"B-ALL\", \"ALL\"])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "\n",
    "confusion_matrix_path = os.path.join(\"plots\", \"confusion_matrix.png\")\n",
    "plt.savefig(confusion_matrix_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Confusion matrix saved to {confusion_matrix_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(fpr, tpr, marker='.', label=f'ROC AUC = {roc_auc:.3f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "x_test_df = pd.DataFrame(x_test, columns=selected_feature_names)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, x_test_df, plot_type=\"bar\", show=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "shap_plot_path = os.path.join(\"plots\", \"shap_summary_plot.png\")\n",
    "plt.savefig(shap_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"SHAP summary plot saved to {shap_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
