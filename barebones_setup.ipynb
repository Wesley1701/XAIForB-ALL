{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Classify B-ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "- After every kernel restart rerun \"Core\"\n",
    "- It's best to restart after you run a training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Core (Always run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import shap\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.utils import shuffle, resample\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "path_to_data = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_all = cudf.read_parquet(f\"{path_to_data}B_ALL.pq\") # Sample names is column\n",
    "df_b_all_healthy = cudf.read_parquet(f\"{path_to_data}B_ALL_HEALTHY.pq\") # Sample names is column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_all_healthy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_b_all = cudf.read_parquet(f\"{path_to_data}B_ALL.pq\") # Sample names is column\n",
    "# df_b_all_healthy = cudf.read_parquet(f\"{path_to_data}B_ALL_healthy.pq\") # Sample names is column\n",
    "# df_mixed_all = cudf.read_parquet(f\"{path_to_data}ALL.pq\") # Sample names is column\n",
    "# df_aml_all = cudf.read_parquet(f\"{path_to_data}AML.pq\") # Sample names is column\n",
    "\n",
    "b_all_length = len(df_b_all.columns.drop(['gene_name', 'gene_type']))  # Exclude non-numeric columns\n",
    "b_all_healthy_length = len(df_b_all_healthy.columns.drop(['gene_name', 'gene_type']))  # Exclude non-numeric columns\n",
    "# mixed_all_length = len(df_mixed_all.columns.drop(['gene_name', 'gene_type']))  # Exclude non-numeric columns\n",
    "# aml_all_length = len(df_aml_all.columns.drop(['gene_name', 'gene_type']))  # Exclude non-numeric columns\n",
    "# total_length = b_all_length + mixed_all_length + aml_all_length\n",
    "# total_length = b_all_length + mixed_all_length\n",
    "total_length = b_all_length + b_all_healthy_length\n",
    "\n",
    "print(\"B-ALL length:\", len(df_b_all))\n",
    "print(\"B-ALL Healthy length:\", len(df_b_all_healthy))\n",
    "\n",
    "df_b_all_filtered = df_b_all[df_b_all['gene_type'] == 'protein_coding']  # Filter for protein-coding genes\n",
    "df_b_all_healthy_filtered = df_b_all_healthy[df_b_all_healthy['gene_type'] == 'protein_coding']  # Filter for protein-coding genes\n",
    "\n",
    "print(\"Filtered B-ALL length:\", len(df_b_all_filtered))\n",
    "print(\"Filtered B-ALL Healthy length:\", len(df_b_all_healthy_filtered))\n",
    "\n",
    "df_b_all_filtered = df_b_all_filtered.drop(['gene_name', 'gene_type'], axis=1)  # Drop non-numeric columns\n",
    "df_b_all_healthy_filtered = df_b_all_healthy_filtered.drop(['gene_name', 'gene_type'], axis=1)  # Drop non-numeric columns\n",
    "\n",
    "df_b_all_filtered = df_b_all_filtered.fillna(0).select_dtypes(include='number').T\n",
    "df_b_all_healthy_filtered = df_b_all_healthy_filtered.fillna(0).select_dtypes(include='number').T\n",
    "\n",
    "# df_b_all_filtered.head()\n",
    "\n",
    "combined_df = cudf.concat([df_b_all_filtered, df_b_all_healthy_filtered], axis=0)\n",
    "\n",
    "# combined_df.tail()\n",
    "\n",
    "combined_df['condition'] = [1] * len(df_b_all_healthy_filtered) + [0] * len(df_b_all_filtered)\n",
    "\n",
    "# combined_df.head()\n",
    "\n",
    "if (len(df_b_all_filtered) + len(df_b_all_healthy_filtered)) != combined_df.shape[0]:\n",
    "    print(f\"Expected number of rows: {len(df_b_all_filtered) + len(df_b_all_healthy_filtered)}, Actual number of rows: {combined_df.shape[0]}\")\n",
    "    raise ValueError(\"The number of rows in the combined DataFrame does not match the sum of B-ALL and B-ALL Healthy lengths.\")\n",
    "\n",
    "# merged_df = df_b_all.merge(df_mixed_all, on='gene_id', how='inner')\n",
    "# merged_df = merged_df.merge(df_aml_all, on='gene_id', how='inner')\n",
    "\n",
    "# merged_df = merged_df[merged_df['gene_type'] == 'protein_coding']  # Filter for protein-coding genes\n",
    "\n",
    "# gene_names = merged_df['gene_name_x']\n",
    "\n",
    "# merged_df_transposed = merged_df.fillna(0)  # Fill NaN values with 0\n",
    "# merged_df_transposed = merged_df.select_dtypes(include='number').T\n",
    "\n",
    "# if total_length != merged_df_transposed.shape[0]:\n",
    "#     print(f\"Expected number of rows: {total_length}, Actual number of rows: {merged_df_transposed.shape[0]}\")\n",
    "#     raise ValueError(\"The number of rows in the merged DataFrame does not match the sum of B-ALL and mixed ALL lengths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.to_pandas()  # Convert to pandas DataFrame for further processing\n",
    "\n",
    "print(f\"Amount of features in the merged DataFrame: {combined_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_transposed = merged_df_transposed.to_pandas()\n",
    "\n",
    "# gene_names = gene_names.to_pandas().reset_index(drop=True)\n",
    "\n",
    "# print(f\"Amount of features in the merged DataFrame: {merged_df_transposed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## XGBoost (Single Test Split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "PU Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = pd.Series([1] * b_all_length + [0] * (mixed_all_length + aml_all_length), index=merged_df_transposed.index)\n",
    "\n",
    "y = combined_df['condition']  # Use the 'condition' column as the target variable\n",
    "\n",
    "# y = pd.Series([1] * b_all_length + [0] * (mixed_all_length), index=merged_df_transposed.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert merged_df_transposed.shape[0] == len(y), \"Mismatch: number of samples in X and labels in y\"\n",
    "# assert merged_df_transposed.index.equals(y.index), \"Mismatch: index order between X and y\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Label shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Log2 Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_normalized = np.log2(combined_df + 1)  # Log2 transformation\n",
    "\n",
    "# merged_df_normalized = np.log2(merged_df_transposed + 1)  # Log2 transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_normalized, y = shuffle(merged_df_normalized, y, random_state=42)\n",
    "\n",
    "merged_df_normalized.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    merged_df_normalized, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Undersampler and oversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy={0: 350}, random_state=42)\n",
    "x_train, y_train = rus.fit_resample(x_train, y_train)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = np.random.normal(0, 0.8, x_train.shape) * x_train\n",
    "\n",
    "# x_train += noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Variance Threshold (Remove constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_vt = VarianceThreshold(threshold=0.0)\n",
    "\n",
    "x_train = selector_vt.fit_transform(x_train)\n",
    "x_test = selector_vt.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector = PCA(n_components=0.95, random_state=42)\n",
    "# x_train = selector.fit_transform(x_noisy)\n",
    "# x_test = selector.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=500)\n",
    "x_train = selector.fit_transform(x_train, y_train)\n",
    "x_test = selector.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fac = 0.1\n",
    "\n",
    "# x_train, y_train = resample(\n",
    "#     x_train, y_train, \n",
    "#     replace=False, \n",
    "#     n_samples=int(len(x_train) * train_fac),\n",
    "#     stratify=y_train,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_names_worst = gene_names.iloc[mixed_indices].reset_index(drop=True)\n",
    "\n",
    "# gene_names = gene_names[selector.get_support(indices=True)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Random features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_train, n_features = x_noisy.shape\n",
    "# n_test = x_test.shape[0]\n",
    "\n",
    "# x_train = np.random.normal(0, 1, size=(n_train, n_features))\n",
    "# x_test = np.random.normal(0, 1, size=(n_test, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of x_train after feature selection: {x_train.shape}\"\n",
    "      f\", Shape of x_test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if x_train.shape[0] != y_train.shape[0] or x_test.shape[0] != y_test.shape[0]:\n",
    "    raise ValueError(\"Mismatch: number of samples in X_train/X_test and labels in y_train/y_test\")\n",
    "\n",
    "if sum(y_train == 1) == 0 or sum(y_train == 0) == 0:\n",
    "    raise ValueError(\"Training set must contain both classes (B-ALL and non-B-ALL).\")\n",
    "\n",
    "if isinstance(y_train, pd.DataFrame) or isinstance(y_test, pd.DataFrame):\n",
    "    raise ValueError(\"y_train and y_test must be Series, not DataFrames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.1,\n",
    "    solver='liblinear',\n",
    "    random_state=42,\n",
    "    max_iter=1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_proba = lr.predict_proba(x_test)[:, 1]\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"AUC: {auc_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_pos_weight = sum(y_train == 0) / sum(y_train == 1)\n",
    "\n",
    "# xgb = XGBClassifier(\n",
    "#     objective=\"binary:logistic\",\n",
    "#     eval_metric=\"auc\",\n",
    "#     use_label_encoder=False,\n",
    "#     # scale_pos_weight=scale_pos_weight,  # Keep this for class imbalance\n",
    "#     tree_method=\"hist\",\n",
    "#     device=\"cuda\",\n",
    "    \n",
    "#     # Core parameters\n",
    "#     n_estimators=500,        # More trees, let early stopping decide\n",
    "#     learning_rate=0.05,      # Moderate learning rate\n",
    "#     max_depth=4,             # Allow some complexity for gene interactions\n",
    "    \n",
    "#     # Regularization (important for high-dimensional genomics)\n",
    "#     reg_lambda=5.0,          # L2 regularization\n",
    "#     reg_alpha=1.0,           # L1 regularization (feature selection)\n",
    "    \n",
    "#     # Sampling (reduces overfitting)\n",
    "#     subsample=0.8,           # Sample 80% of rows\n",
    "#     colsample_bytree=0.8,    # Sample 80% of features per tree\n",
    "#     colsample_bylevel=0.8,   # Additional feature sampling\n",
    "    \n",
    "#     # Early stopping\n",
    "#     early_stopping_rounds=50,  # Stop if no improvement\n",
    "    \n",
    "#     # Reproducibility\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# xgb = XGBClassifier(\n",
    "#     objective=\"binary:logistic\",\n",
    "#     eval_metric=\"auc\",\n",
    "#     use_label_encoder=False,\n",
    "#     tree_method=\"hist\",\n",
    "#     device=\"cuda\",\n",
    "    \n",
    "#     # Reduced model complexity\n",
    "#     n_estimators=50,          # Much fewer trees (was 500)\n",
    "#     learning_rate=0.3,        # Higher learning rate for faster, less precise learning\n",
    "#     max_depth=2,              # Shallow trees (was 4)\n",
    "    \n",
    "#     # Increased regularization\n",
    "#     reg_lambda=20.0,          # Much higher L2 regularization (was 5.0)\n",
    "#     reg_alpha=10.0,           # Higher L1 regularization (was 1.0)\n",
    "    \n",
    "#     # More aggressive sampling\n",
    "#     subsample=0.5,            # Sample only 50% of rows (was 0.8)\n",
    "#     colsample_bytree=0.5,     # Sample only 50% of features per tree (was 0.8)\n",
    "#     colsample_bylevel=0.5,    # More aggressive feature sampling (was 0.8)\n",
    "    \n",
    "#     # Early stopping (keep as is)\n",
    "#     early_stopping_rounds=20, # Stop earlier (was 50)\n",
    "    \n",
    "#     # Reproducibility\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# xgb.fit(x_train, y_train, eval_set=[(x_test, y_test)], verbose=True)\n",
    "\n",
    "# gpu_x_test = DMatrix(x_test, y_test)\n",
    "\n",
    "# y_pred = xgb.get_booster().predict(gpu_x_test)\n",
    "\n",
    "# y_proba = xgb.predict_proba(x_test)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# auc_score = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# print(f\"AUC: {auc_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Statistics and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Check seperator genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "\n",
    "gene_aucs = []\n",
    "\n",
    "for i in range(x_train.shape[1]):\n",
    "    gene_values = x_train[:, i]\n",
    "    try:\n",
    "        auc_value = roc_auc_score(y_train, gene_values)\n",
    "        gene_aucs.append((i, auc_value))\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "gene_aucs = np.array(gene_aucs, dtype=[('index', int), ('auc', float)])\n",
    "\n",
    "gene_aucs_df = pd.DataFrame({\n",
    "    \"gene\": gene_aucs['index'],\n",
    "    \"auc\": gene_aucs['auc']\n",
    "})\n",
    "gene_aucs_df[\"auc_diff\"] = abs(gene_aucs_df[\"auc\"] - 0.5)  # How far from random\n",
    "gene_aucs_df = gene_aucs_df.sort_values(\"auc_diff\", ascending=False)\n",
    "\n",
    "top_genes = gene_aucs_df.head(5)['gene'].astype(int).tolist()\n",
    "\n",
    "for i in top_genes[:5]:  # visualize top 5 for example\n",
    "    # Create a DataFrame manually\n",
    "    df_plot = pd.DataFrame({\n",
    "        'Expression': x_train[:, i],\n",
    "        'Class': y_train\n",
    "    })\n",
    "    sns.boxplot(data=df_plot, x='Class', y='Expression')\n",
    "    plt.title(f'Expression of Gene by Class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "Plot Prediction Score Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap predictions into a DataFrame for easier slicing\n",
    "df_scores = pd.DataFrame({\n",
    "    \"B_ALL_score\": y_proba,\n",
    "    \"Label\": y_test  # ensure matching index\n",
    "})\n",
    "\n",
    "# Plot for known B-ALL (positives)\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.histplot(df_scores[df_scores[\"Label\"] == 1][\"B_ALL_score\"], color=\"blue\", bins=25, kde=True)\n",
    "plt.title(\"Predicted B-ALL Score — Known B-ALL Samples\")\n",
    "plt.xlabel(\"Predicted Probability of B-ALL\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for unlabeled/mixed\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.histplot(df_scores[df_scores[\"Label\"] == 0][\"B_ALL_score\"], color=\"red\", bins=25, kde=True)\n",
    "plt.title(\"Predicted B-ALL Score — Unlabeled Samples\")\n",
    "plt.xlabel(\"Predicted Probability of B-ALL\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_named = pd.DataFrame(x_test, columns=gene_names)\n",
    "\n",
    "# x_test_named.head()\n",
    "\n",
    "# Use the actual gene names directly\n",
    "# explainer = shap.TreeExplainer(xgb)\n",
    "explainer = shap.LinearExplainer(lr, x_train, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "shap.summary_plot(shap_values, x_test, \n",
    "                  plot_type=\"violin\", \n",
    "                  max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x_test, plot_type=\"bar\", max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## XGBoost (Stratified KFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "#### PU Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series([1] * b_all_length + [0] * (mixed_all_length), index=merged_df_transposed.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert merged_df_transposed.shape[0] == len(y), \"Mismatch: number of samples in X and labels in y\"\n",
    "assert merged_df_transposed.index.equals(y.index), \"Mismatch: index order between X and y\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "\n",
    "x = merged_df_transposed\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(x, y)):\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "\n",
    "    x_train_fold, x_val_fold = x.iloc[train_index], x.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    x_train_fold = np.log2(x_train_fold + 1)  # Log2 transformation\n",
    "    x_val_fold = np.log2(x_val_fold + 1)      # Log2 transformation\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_fold = scaler.fit_transform(x_train_fold)\n",
    "    x_val_fold = scaler.transform(x_val_fold)\n",
    "\n",
    "    selector = SelectKBest(score_func=f_classif, k=5)\n",
    "    x_train_fold = selector.fit_transform(x_train_fold, y_train_fold)\n",
    "    x_val_fold = selector.transform(x_val_fold)\n",
    "\n",
    "    scale_pos_weight = sum(y_train_fold == 0) / sum(y_train_fold == 1)\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        use_label_encoder=False,\n",
    "        scale_pos_weight=scale_pos_weight,  # Keep this for class imbalance\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        \n",
    "        # Core parameters\n",
    "        n_estimators=500,        # More trees, let early stopping decide\n",
    "        learning_rate=0.05,      # Moderate learning rate\n",
    "        max_depth=4,             # Allow some complexity for gene interactions\n",
    "        \n",
    "        # Regularization (important for high-dimensional genomics)\n",
    "        reg_lambda=5.0,          # L2 regularization\n",
    "        reg_alpha=1.0,           # L1 regularization (feature selection)\n",
    "        \n",
    "        # Sampling (reduces overfitting)\n",
    "        subsample=0.8,           # Sample 80% of rows\n",
    "        colsample_bytree=0.8,    # Sample 80% of features per tree\n",
    "        colsample_bylevel=0.8,   # Additional feature sampling\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping_rounds=50,  # Stop if no improvement\n",
    "        \n",
    "        # Reproducibility\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb.fit(x_train_fold, y_train_fold, eval_set=[(x_val_fold, y_val_fold)], verbose=False)\n",
    "\n",
    "    y_proba = xgb.predict_proba(x_val_fold)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "    auc_fold = roc_auc_score(y_val_fold, y_proba)\n",
    "\n",
    "    auc_scores.append(auc_fold)\n",
    "\n",
    "    print(f\"Fold {fold + 1}, AUC: {auc_fold:.3f}\")\n",
    "\n",
    "print(f\"Mean AUC across all folds: {np.mean(auc_scores):.3f} ± {np.std(auc_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### Statistics and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(auc_scores, kde=True, bins=5)\n",
    "plt.title(\"Distribution of AUC Scores Across Folds\")\n",
    "plt.xlabel(\"AUC\")\n",
    "plt.ylabel(\"Number of Folds\")\n",
    "plt.axvline(np.mean(auc_scores), color=\"red\", linestyle=\"--\", label=\"Mean AUC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
