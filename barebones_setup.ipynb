{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### (ATTENTION: To use the standard pandas not the GPU version, uncomment the pandas import and comment the cudf comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as pd\n",
    "# import pandas as pd\n",
    "from cudf import DataFrame\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "path_to_data = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Actual Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Preprocessing healthy: dataset | Drop operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_healthy_csv_path = os.path.join(path_to_data, \"raw_healthy_data.csv\")\n",
    "\n",
    "raw_healthy_df = pd.read_csv(raw_healthy_csv_path, index_col=0, header=0,  sep=',')\n",
    "\n",
    "raw_healthy_df.drop('Description', axis=1, inplace=True)\n",
    "\n",
    "if raw_healthy_df.dtypes.nunique() > 1:\n",
    "    raise ValueError(\"DataFrame contains multiple data types, which is not supported.\")\n",
    "\n",
    "raw_healthy_df = raw_healthy_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Preprocessing unhealthy: dataset | Drop operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_unhealthy_csv_path = os.path.join(path_to_data, \"raw_unhealthy_data.csv\")\n",
    "\n",
    "raw_unhealthy_df = pd.read_csv(raw_unhealthy_csv_path, nrows=1, index_col=0, header=0, sep=',')\n",
    "\n",
    "b_all_gene_markers = [\n",
    "    'CD19', 'CD22', 'CD79A', 'CD10', 'BCR-ABL1', 'ETV6-RUNX1',\n",
    "    'TCF3-PBX1', 'KMT2A-AF4', 'CRLF2', 'IKZF1', 'PAX5', 'JAK1', 'JAK2',\n",
    "    'ABL1', 'ABL2', 'CSF1R', 'PDGFRB', 'NRAS', 'KRAS', 'PTPN11'\n",
    "]\n",
    "\n",
    "raw_unhealthy_df.head()\n",
    "\n",
    "# all_genes_in_row  = raw_unhealthy_df.iloc[0]\n",
    "\n",
    "# print(f\"All genes in the first row: {all_genes_in_row.to_arrow().to_pylist()}\")\n",
    "\n",
    "# print(f\"b_ALL gene markers: {b_all_gene_markers}\")\n",
    "# print(f\"Genes in the first row: {all_genes_in_row.tolist()}\")\n",
    "\n",
    "# b_all_genes_mask = all_genes_in_row.isin(b_all_gene_markers)\n",
    "\n",
    "# b_all_genes = all_genes_in_row[b_all_genes_mask]\n",
    "\n",
    "# print(b_all_genes)\n",
    "\n",
    "# genes_found = pd.Series(all_genes_in_row).isin(b_all_gene_markers)\n",
    "\n",
    "# print(f\"Genes found in the first row: {genes_found.tolist()}\")\n",
    "\n",
    "# raw_unhealthy_df.head()\n",
    "\n",
    "# print(raw_unhealthy_df.iloc[1])\n",
    "\n",
    "# print(f\"Genes found in the DataFrame: {genes_found.tolist()}\")\n",
    "\n",
    "# has_b_all_marker = raw_unhealthy_df.iloc[0].isin(b_all_gene_markers)\n",
    "\n",
    "# print(f\"Does the DataFrame contain any B-ALL gene markers? {has_b_all_marker}\")\n",
    "\n",
    "# raw_unhealthy_df.drop('gene_name', inplace=True)\n",
    "# raw_unhealthy_df.drop('gene_type', inplace=True)\n",
    "\n",
    "# raw_unhealthy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Preprocessing healthy: gencode processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_column_names = raw_healthy_df.columns.str.split('.').str[0]\n",
    "\n",
    "columns_to_keep_mask = ~temp_column_names.duplicated(keep='first')\n",
    "\n",
    "print(\"Total columns before removal:\", len(raw_healthy_df.columns))\n",
    "\n",
    "raw_healthy_df_cleaned = raw_healthy_df.loc[:, columns_to_keep_mask]\n",
    "raw_healthy_df_cleaned.columns = temp_column_names[columns_to_keep_mask]\n",
    "\n",
    "raw_healthy_df = raw_healthy_df_cleaned\n",
    "\n",
    "del raw_healthy_df_cleaned  # Free memory\n",
    "\n",
    "print(\"Total columns after removal:\", len(raw_healthy_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Preprocessing unhealthy: gencode processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_column_names = raw_unhealthy_df.columns.str.split('.').str[0]\n",
    "\n",
    "columns_to_keep_mask = ~temp_column_names.duplicated(keep='first')\n",
    "\n",
    "print(\"Total columns before removal:\", len(raw_unhealthy_df.columns))\n",
    "\n",
    "raw_unhealthy_df_cleaned = raw_unhealthy_df.loc[:, columns_to_keep_mask]\n",
    "raw_unhealthy_df_cleaned.columns = temp_column_names[columns_to_keep_mask]\n",
    "\n",
    "raw_unhealthy_df = raw_unhealthy_df_cleaned\n",
    "\n",
    "del raw_unhealthy_df_cleaned  # Free memory\n",
    "\n",
    "print(\"Total columns after removal:\", len(raw_unhealthy_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Preprocessing healthy: Convert dtypes to int32 and drop NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_healthy_df = raw_healthy_df.astype(np.int32)\n",
    "raw_healthy_df.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Preprocessing unhealthy: Convert dtypes to int32 and drop NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_unhealthy_df = raw_unhealthy_df.astype(np.int32)\n",
    "raw_unhealthy_df.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Preprocessing: selecting only common genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_genes = raw_healthy_df.columns.intersection(raw_unhealthy_df.columns)\n",
    "\n",
    "unhealthy_df_rows_length = len(raw_unhealthy_df)\n",
    "\n",
    "raw_healthy_df_filtered = raw_healthy_df[matching_genes]\n",
    "\n",
    "raw_unhealthy_df_filtered = raw_unhealthy_df[matching_genes]\n",
    "\n",
    "raw_healthy_df_filtered = raw_healthy_df_filtered.drop(raw_healthy_df_filtered.index[-(len(raw_healthy_df_filtered) - unhealthy_df_rows_length):])\n",
    "\n",
    "if len(raw_healthy_df_filtered) != unhealthy_df_rows_length:\n",
    "    raise ValueError(\"The number of rows in the healthy DataFrame does not match the unhealthy DataFrame after slicing.\")\n",
    "\n",
    "print(f\"Healthy DataFrame rows after slicing: {len(raw_healthy_df_filtered)}\")\n",
    "print(f\"Unhealthy DataFrame rows: {unhealthy_df_rows_length}\")\n",
    "\n",
    "print(\"Healthy DataFrame columns:\", len(raw_healthy_df_filtered.columns))\n",
    "print(\"Unhealthy DataFrame columns:\", len(raw_unhealthy_df_filtered.columns))\n",
    "\n",
    "raw_healthy_df = raw_healthy_df_filtered\n",
    "\n",
    "raw_unhealthy_df = raw_unhealthy_df_filtered\n",
    "\n",
    "del raw_healthy_df_filtered\n",
    "del raw_unhealthy_df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Preprocessing: add condition column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_unhealthy_df[\"condition\"] = 0\n",
    "raw_healthy_df[\"condition\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Preprocessing: change index name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_unhealthy_df_filtered.index.name = \"sample_id\"\n",
    "# raw_healthy_df_filtered.index.name = \"sample_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Debug checks (can be commented out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_healthy_df_filtered.info()\n",
    "# raw_healthy_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_healthy_df_filtered.info()\n",
    "# raw_unhealthy_df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Final checks before merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "are_column_names_same_regardless_order = set(raw_healthy_df.columns) == set(raw_unhealthy_df.columns)\n",
    "\n",
    "if not are_column_names_same_regardless_order:\n",
    "    raise ValueError(\"Column names in healthy and unhealthy DataFrames do not match.\")\n",
    "\n",
    "if raw_healthy_df.duplicated().any():\n",
    "    raise ValueError(\"Healthy DataFrame contains duplicate rows.\")\n",
    "\n",
    "if raw_unhealthy_df.duplicated().any():\n",
    "    raise ValueError(\"Unhealthy DataFrame contains duplicate rows.\")\n",
    "\n",
    "if raw_healthy_df.columns.duplicated().any():\n",
    "    raise ValueError(\"Healthy DataFrame contains duplicate columns.\")\n",
    "\n",
    "if raw_unhealthy_df.columns.duplicated().any():\n",
    "    raise ValueError(\"Unhealthy DataFrame contains duplicate columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Do merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df: DataFrame = pd.concat([raw_healthy_df, raw_unhealthy_df], axis=0)\n",
    "\n",
    "\n",
    "merged_df.to_parquet(f\"{path_to_data}merged_data.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "print(f\"Data processing completed in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# Preprocessing V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as pd\n",
    "from cudf import DataFrame\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pandas import melt, merge\n",
    "import numpy as np\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "path_to_data = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## Preprocessing: T-Cell extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mixed_all = pd.read_parquet(f\"{path_to_data}ALL.pq\")\n",
    "df_b_all = pd.read_parquet(f\"{path_to_data}B_ALL.pq\")\n",
    "\n",
    "t_cell_genes = [\n",
    "    'CD2', 'CD3D', 'CD3E', 'CD3G', 'CD4', 'CD6', 'CD7', 'TCF7', 'GATA3',\n",
    "    'HOXA1', 'HOXA2', 'HOXA3', 'HOXA5', 'HOXA6', 'HOXA9', 'HOXA11', 'HOXA13',\n",
    "    'LMO3', 'LAG3', 'FOXP3', 'ITGAL', 'TNFRSF9', 'TCL1A', 'NOTCH3'\n",
    "]\n",
    "\n",
    "df_mixed_all.columns = df_mixed_all.columns.str.strip()\n",
    "\n",
    "df_b_all.columns = df_b_all.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_all_samples = df_mixed_all[df_mixed_all['gene_name'].isin(t_cell_genes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_all_samples_dropped_cols = t_all_samples.drop(columns=['gene_name', 'gene_type'])\n",
    "\n",
    "df_b_all_dropped_cols = df_b_all.drop(columns=['gene_name', 'gene_type'])\n",
    "\n",
    "t_all_transposed = t_all_samples_dropped_cols.T\n",
    "\n",
    "b_all_transposed = df_b_all_dropped_cols.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_all_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_all_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df: DataFrame = pd.concat([b_all_transposed, t_all_transposed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the lengths of the DataFrames\n",
    "all_length = len(t_all_transposed)\n",
    "b_all_length = len(b_all_transposed)\n",
    "sum_length = all_length + b_all_length\n",
    "combined_length = len(combined_df)\n",
    "\n",
    "print(f\"Length of ALL samples: {all_length}\")\n",
    "print(f\"Length of B-ALL samples: {b_all_length}\")\n",
    "print(f\"Sum of lengths: {sum_length}\")\n",
    "print(f\"Length of combined DataFrame: {combined_length}\")\n",
    "\n",
    "if sum_length != combined_length:\n",
    "    raise ValueError(\"The combined DataFrame does not match the sum of the individual DataFrames' lengths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.reset_index(inplace=True)\n",
    "\n",
    "combined_df.rename(columns={'index': 'sample_id'}, inplace=True)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = combined_df.to_pandas().select_dtypes(include=\"number\")\n",
    "\n",
    "cupy_array = cp.asarray(numeric_df.values)\n",
    "\n",
    "x_log2 = cp.log2(cupy_array + 1)\n",
    "\n",
    "normalized_df = pd.DataFrame(cp.asnumpy(x_log2), columns=numeric_df.columns, index=numeric_df.index)\n",
    "normalized_df = pd.concat([combined_df[['sample_id']], normalized_df], axis=1)\n",
    "\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_all_labels = pd.Series(['T-ALL'] * t_all_transposed.shape[0], index=t_all_transposed.index)\n",
    "\n",
    "final_combined_labels = pd.concat([\n",
    "    pd.Series(['B-ALL'] * b_all_transposed.shape[0], index=b_all_transposed.index),\n",
    "    t_all_labels\n",
    "])\n",
    "\n",
    "final_combined_labels = final_combined_labels.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_combined_df = melt(normalized_df.to_pandas(), id_vars=['sample_id'], var_name='Gene', value_name='Expression')\n",
    "\n",
    "melted_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_combined_df = merge(melted_combined_df, final_combined_labels.rename(\"Diagnosis\"), left_on='sample_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_to_plot = [\n",
    "    'ENSG00000000003.15',\n",
    "    \"ENSG00000005073.6\"\n",
    "]\n",
    "\n",
    "plot_data_filtered_genes = merged_combined_df[merged_combined_df['Gene'].isin(genes_to_plot)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create the plot ---\n",
    "plt.figure(figsize=(15, 6 * len(genes_to_plot))) # Adjust figure size dynamically based on number of genes\n",
    "# Using a FacetGrid to create a separate plot for each gene\n",
    "g = sns.catplot(\n",
    "    data=plot_data_filtered_genes,\n",
    "    x='Diagnosis',      # Categorical variable on the x-axis\n",
    "    y='Expression',     # Numerical variable on the y-axis\n",
    "    col='Gene',         # Create separate columns of plots for each gene\n",
    "    col_wrap=len(genes_to_plot), # Wrap columns if you have many genes, adjust as needed\n",
    "    kind='box',         # Use 'box' for box plot, or 'violin' for violin plot\n",
    "    height=5,           # Height of each facet\n",
    "    aspect=1.2,         # Aspect ratio of each facet\n",
    "    palette='viridis',  # Color palette for diagnoses\n",
    "    sharey=False,       # Allow each gene plot to have its own y-axis scale\n",
    ")\n",
    "\n",
    "# --- Customize the plots ---\n",
    "g.set_axis_labels(\"Diagnosis\", \"Gene Expression (log2CPM or similar)\")\n",
    "g.set_titles(col_template=\"{col_name}\") # Set title for each column (gene name)\n",
    "g.set_xticklabels(rotation=45, ha='right') # Rotate x-axis labels for better readability if diagnosis names are long\n",
    "\n",
    "# Add a main title for the entire figure\n",
    "plt.suptitle('Gene Expression Across Diagnosis Groups', y=1.02, fontsize=16) # Adjust y for title position\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout to prevent title overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "print(f\"Data processing for T-cell genes completed in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "# Model training V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "1. Change condition from \"subtype\" to something else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as pd\n",
    "from cudf import DataFrame\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pandas import melt, merge\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cuml as cm\n",
    "from cuml.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "path_to_data = \"data/\"\n",
    "\n",
    "T_ALL_LABEL = \"T-ALL\"\n",
    "B_ALL_LABEL = \"B-ALL\"\n",
    "ETP_LABEL = \"ETP-ALL\"\n",
    "MPAL_LABEL = \"MPAL\"\n",
    "AML_LABEL = \"AML\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mixed_all = pd.read_parquet(f\"{path_to_data}ALL.pq\")\n",
    "df_b_all = pd.read_parquet(f\"{path_to_data}B_ALL.pq\")\n",
    "# df_aml = pd.read_parquet(f\"{path_to_data}AML.pq\")\n",
    "\n",
    "t_cell_genes = [\n",
    "    'CD2', 'CD3D', 'CD3E', 'CD3G', 'CD4', 'CD6', 'CD7', 'TCF7', 'GATA3',\n",
    "    'HOXA1', 'HOXA2', 'HOXA3', 'HOXA5', 'HOXA6', 'HOXA9', 'HOXA11', 'HOXA13',\n",
    "    'LMO3', 'LAG3', 'FOXP3', 'ITGAL', 'TNFRSF9', 'TCL1A', 'NOTCH3'\n",
    "]\n",
    "\n",
    "etp_markers = [\n",
    "    \"CD7\", \"CD34\", \"KIT\", \"CD117\", \"CD33\", \"CD13\", \"HLA-DR\", \"WT1\", \"LYL1\",\n",
    "    \"MEF2C\", \"BAALC\", \"HHEX\", \"FLT3\", \"DNMT3A\", \"EZH2\", \"PHF6\"\n",
    "]\n",
    "\n",
    "mpal_markers = [\n",
    "    \"CD3\", \"CD19\", \"CD33\", \"CD13\", \"MPO\", \"CD22\", \"CD79A\", \"CD10\",\n",
    "    \"KMT2A\", \"RUNX1\", \"NPM1\", \"IKZF1\", \"CRLF2\", \"CSF1R\", \"PDGFRB\"\n",
    "]\n",
    "\n",
    "t_all_samples = df_mixed_all[df_mixed_all['gene_name'].isin(t_cell_genes)]\n",
    "\n",
    "if t_all_samples.empty:\n",
    "    raise ValueError(\"No T-cell genes found in the mixed ALL DataFrame.\")\n",
    "\n",
    "etp_samples = df_mixed_all[df_mixed_all['gene_name'].isin(etp_markers)]\n",
    "\n",
    "if etp_samples.empty:\n",
    "    raise ValueError(\"No ETP-MPAL markers found in the mixed ALL DataFrame.\")\n",
    "\n",
    "mpal_samples = df_mixed_all[df_mixed_all['gene_name'].isin(mpal_markers)]\n",
    "\n",
    "if mpal_samples.empty:\n",
    "    raise ValueError(\"No MPAL markers found in the mixed ALL DataFrame.\")\n",
    "\n",
    "t_all_samples_dropped_cols = t_all_samples.drop(columns=['gene_name', 'gene_type'])\n",
    "etp_samples = etp_samples.drop(columns=['gene_name', 'gene_type'])\n",
    "mpal_samples = mpal_samples.drop(columns=['gene_name', 'gene_type'])\n",
    "\n",
    "df_b_all_dropped_cols = df_b_all.drop(columns=['gene_name', 'gene_type'])\n",
    "# df_aml_dropped_cols = df_aml.drop(columns=['gene_name', 'gene_type'])\n",
    "\n",
    "t_all_transposed = t_all_samples_dropped_cols.T\n",
    "etp_transposed = etp_samples.T\n",
    "mpal_transposed = mpal_samples.T\n",
    "b_all_transposed = df_b_all_dropped_cols.T\n",
    "# aml_transposed = df_aml_dropped_cols.T\n",
    "\n",
    "t_all_transposed[\"subtype\"] = T_ALL_LABEL\n",
    "etp_transposed[\"subtype\"] = ETP_LABEL\n",
    "mpal_transposed[\"subtype\"] = MPAL_LABEL\n",
    "b_all_transposed[\"subtype\"] = B_ALL_LABEL\n",
    "# aml_transposed[\"subtype\"] = AML_LABEL\n",
    "\n",
    "t_all_transposed.reset_index(inplace=True)\n",
    "etp_transposed.reset_index(inplace=True)\n",
    "mpal_transposed.reset_index(inplace=True)\n",
    "b_all_transposed.reset_index(inplace=True)\n",
    "# aml_transposed.reset_index(inplace=True)\n",
    "\n",
    "t_all_transposed.rename(columns={'index': 'sample_id'}, inplace=True)\n",
    "etp_transposed.rename(columns={'index': 'sample_id'}, inplace=True)\n",
    "mpal_transposed.rename(columns={'index': 'sample_id'}, inplace=True)\n",
    "b_all_transposed.rename(columns={'index': 'sample_id'}, inplace=True)\n",
    "# aml_transposed.rename(columns={'index': 'sample_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df: DataFrame = pd.concat([b_all_transposed, t_all_transposed, etp_transposed, mpal_transposed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = combined_df[\"sample_id\"]\n",
    "\n",
    "y = combined_df[\"subtype\"]\n",
    "x = combined_df.drop(columns=[\"sample_id\", \"subtype\"])\n",
    "\n",
    "le = cm.preprocessing.LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = cm.model_selection.train_test_split(\n",
    "    x, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### Variance filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "var = x_train.var()\n",
    "\n",
    "top_n_cols = var.nlargest(N).index.to_arrow().to_pylist()\n",
    "\n",
    "x_train = x_train[top_n_cols]\n",
    "x_test = x_test[top_n_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = cm.preprocessing.StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "### Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy = x_train_scaled.to_numpy()\n",
    "\n",
    "noise = np.random.normal(loc=0, scale=0.1, size=x_train_noisy.shape)\n",
    "\n",
    "x_train_noisy += noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    scale_pos_weight=None,\n",
    "    tree_method=\"gpu_hist\",   # Use \"hist\" for CPU\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "weight_map = {\n",
    "    0: 1.0,\n",
    "    1: 2.08,\n",
    "    2: 2.08,\n",
    "    3: 2.08\n",
    "}\n",
    "\n",
    "# Convert labels to per-sample weights\n",
    "sample_weight = np.array([weight_map[label] for label in y_train.to_arrow().to_pylist()])\n",
    "\n",
    "xgb.fit(x_train_noisy, y_train, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test_np, y_pred):.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_np, y_pred))\n",
    "\n",
    "# Per-class metrics (precision, recall, F1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_np, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "## Statistics and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = combined_df.drop(columns=[\"sample_id\", \"subtype\"])\n",
    "y = combined_df[\"subtype\"].to_arrow().to_pylist()\n",
    "\n",
    "# Drop low-variance genes (e.g., keep top 2000 most variable)\n",
    "gene_variances = x_full.var(axis=0)\n",
    "top_genes = gene_variances.sort_values(ascending=False).head(2000).index\n",
    "\n",
    "# Filter to only those genes\n",
    "X_reduced = x_full[top_genes.to_arrow().to_pylist()]\n",
    "\n",
    "# Impute missing gene values with column mean\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "x_imputed = imputer.fit_transform(X_reduced.to_pandas().values)\n",
    "\n",
    "# Scale\n",
    "scaler = cm.preprocessing.StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x_imputed)  # or X_filled\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Wrap and plot\n",
    "pca_df = pd.DataFrame(X_pca, columns=[\"PC1\", \"PC2\"])\n",
    "pca_df[\"subtype\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=pca_df.to_pandas(), x=\"PC1\", y=\"PC2\", hue=\"subtype\", style=\"subtype\", s=60)\n",
    "plt.title(\"PCA (Missing Genes Imputed for Plotting)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance: PC1 = {explained[0]*100:.2f}%, PC2 = {explained[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "# Statistics and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as pd\n",
    "import cuml as sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "### PCA Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{path_to_data}merged_data.pq\")\n",
    "\n",
    "x = df.drop(columns=[\"condition\"])\n",
    "\n",
    "y = df[\"condition\"]\n",
    "\n",
    "gene_columns = x.columns\n",
    "mean_healthy = x[y == 1][gene_columns].mean()\n",
    "mean_unhealthy = x[y == 0][gene_columns].mean()\n",
    "mean_diff = (mean_healthy - mean_unhealthy).abs()\n",
    "\n",
    "print(\"\\nHead of Mean Differences (for top 5 genes):\")\n",
    "print(mean_diff.head())\n",
    "\n",
    "k_genes = 10000\n",
    "\n",
    "top_k_genes = mean_diff.nlargest(k_genes).index.to_pandas()\n",
    "\n",
    "x_selected = x[top_k_genes]\n",
    "\n",
    "print(f\"\\nOriginal number of genes: {x.shape[1]}\")\n",
    "\n",
    "print(f\"Number of genes after aggressive selection (top {k_genes} by mean difference): {x_selected.shape[1]}\")\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "x_scaled = scaler.fit_transform(x_selected)\n",
    "\n",
    "print(\"Shape of x_scaled:\", x_scaled.shape)\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "pca_df = pca.fit_transform(x_scaled)\n",
    "\n",
    "print(\"Shape of principal components:\", pca_df.shape)\n",
    "\n",
    "pca_df.columns = [\"PC1\", \"PC2\"]\n",
    "pca_df.index = x_selected.index\n",
    "pca_df[\"condition\"] = y\n",
    "pca_df = pca_df.to_pandas()\n",
    "\n",
    "print(f\"Shape of PCA DataFrame: {pca_df.shape}\")\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(f\"PC1: {pca.explained_variance_ratio_[0]:.4f}\")\n",
    "print(f\"PC2: {pca.explained_variance_ratio_[1]:.4f}\")\n",
    "print(f\"Total Explained Variance (PC1 + PC2): {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "print(\"Generating PCA plot...\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"condition\", palette='viridis', alpha=0.7, s=50)\n",
    "\n",
    "plt.title('PCA of Gene Expression Data (Healthy vs. Unhealthy Samples)')\n",
    "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]*100:.2f}% Variance Explained)')\n",
    "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]*100:.2f}% Variance Explained)')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(title='Condition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as pd\n",
    "import cuml as sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading merged data from Parquet file...\")\n",
    "\n",
    "df = pd.read_parquet(f\"{path_to_data}merged_data.pq\")\n",
    "\n",
    "x = df.drop(columns=[\"condition\"])\n",
    "\n",
    "gene_columns = x.columns\n",
    "\n",
    "y = df[\"condition\"]\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "### Variance thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying variance thresholding...\")\n",
    "\n",
    "print(f\"Original number of genes: {len(gene_columns)}\")\n",
    "\n",
    "x_np = x.to_numpy()\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "selector.fit(x_np)\n",
    "\n",
    "selector_gene_mask = selector.get_support()\n",
    "\n",
    "gene_columns_temp = gene_columns[selector_gene_mask]\n",
    "x_filtered_variance = x[gene_columns_temp]\n",
    "\n",
    "print(f\"Number of genes after variance thresholding: {len(gene_columns_temp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "### Expression filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Low expression filtering...\")\n",
    "\n",
    "print(f\"Number of genes before low expression filtering: {len(x_filtered_variance.columns)}\")\n",
    "\n",
    "gene_means = x_filtered_variance.mean()\n",
    "\n",
    "low_expression_threshold = 0.1\n",
    "\n",
    "gene_columns = gene_means[gene_means > low_expression_threshold].index.to_pandas()\n",
    "\n",
    "x_filtered_low_expression = x_filtered_variance[gene_columns]\n",
    "\n",
    "print(f\"Number of genes after low expression filtering: {len(gene_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting data into training and testing sets...\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    x_filtered_low_expression, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "### Agressive feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aggressive gene selection based on mean differences...\")\n",
    "\n",
    "print(\"Number of genes before selection:\", x_train.shape[1])\n",
    "\n",
    "mean_healthy = x_train[y_train == 1][gene_columns].mean()\n",
    "\n",
    "mean_unhealthy = x_train[y_train == 0][gene_columns].mean()\n",
    "\n",
    "mean_diff = (mean_healthy - mean_unhealthy).abs()\n",
    "\n",
    "k_genes = 2000\n",
    "\n",
    "print(f\"Selecting top {k_genes} genes based on mean differences...\")\n",
    "\n",
    "top_k_genes = mean_diff.nlargest(k_genes).index.to_pandas()\n",
    "\n",
    "x_train_selected = x_train[top_k_genes]\n",
    "x_test_selected = x_test[top_k_genes]\n",
    "\n",
    "print(f\"Number of genes after aggressive selection: {x_train_selected.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "### Scaling gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scaling selected gene expression data...\")\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_selected)\n",
    "x_test_scaled = scaler.transform(x_test_selected)\n",
    "\n",
    "print(\"Shape of x_train_scaled:\", x_train_scaled.shape)\n",
    "print(\"Shape of x_test_scaled:\", x_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "## Logistical regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "### Logistic regression (to prevent perfect seperators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training logistical regression model...\")\n",
    "\n",
    "logreg_model = sklearn.linear_model.LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.0001, \n",
    "    solver='qn',\n",
    "    max_iter=1000, \n",
    ")\n",
    "\n",
    "logreg_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "### Logistic regression prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = logreg_model.predict(x_test_scaled)\n",
    "\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_pred_logreg_np = y_pred_logreg.to_numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_test_np, y_pred_logreg_np)\n",
    "precision = precision_score(y_test_np, y_pred_logreg_np, average='binary')\n",
    "recall = recall_score(y_test_np, y_pred_logreg_np, average='binary')\n",
    "f1 = f1_score(y_test_np, y_pred_logreg_np, average='binary')\n",
    "\n",
    "print(f\"Logistic Regression Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
