{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata_mapping(metadata_file: str) -> dict:\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    sample_sheet_df = pd.read_table('./assets/sample_sheet/sample_sheet.tsv', sep='\\t')\n",
    "\n",
    "    file_to_sample_mapping = {}\n",
    "\n",
    "    for entry in metadata:\n",
    "        file_name = entry.get('file_name')\n",
    "\n",
    "        sample_id = sample_sheet_df[sample_sheet_df[\"File Name\"] == file_name][\"Sample ID\"].values[0]\n",
    "\n",
    "        sample_id = sample_id[:-1]  # Remove last letter because Sample ID in sample sheet includes an A at the end. Further research.\n",
    "        \n",
    "        if not sample_id:\n",
    "            logger.warning(f\"No sample ID found for file: {file_name}\")\n",
    "        else:\n",
    "            file_to_sample_mapping[file_name] = sample_id\n",
    "\n",
    "    logger.info(f\"Loaded metadata mapping for {len(file_to_sample_mapping)} files\")\n",
    "    return file_to_sample_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tsv_file(file_path):\n",
    "    try:\n",
    "        # Read the TSV file, skipping the first comment line\n",
    "        df = pd.read_csv(file_path, skiprows=1, sep='\\t')\n",
    "\n",
    "        # Check if required columns exist\n",
    "        required_cols = ['gene_id', 'tpm_unstranded']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            logger.warning(f\"Required columns not found in {file_path}. Available columns: {df.columns.tolist()}\")\n",
    "            return None\n",
    "\n",
    "        # Filter out rows that start with 'N_' (metadata rows)\n",
    "        df_filtered = df[~df['gene_id'].str.startswith('N_', na=False)]\n",
    "\n",
    "        # Set gene_id as index and select tpm_unstranded column\n",
    "        df_processed = df_filtered.set_index('gene_id')['tpm_unstranded']\n",
    "\n",
    "        return df_processed\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_gdc_files(tsv_directory, metadata_file, output_file):\n",
    "    # Load metadata mapping\n",
    "    file_to_sample_mapping = load_metadata_mapping(metadata_file)\n",
    "\n",
    "    # Get all TSV files\n",
    "    tsv_path = Path(tsv_directory)\n",
    "    tsv_files = list(tsv_path.glob(\"*.tsv\"))\n",
    "\n",
    "    logger.info(f\"Found {len(tsv_files)} TSV files\")\n",
    "\n",
    "    # Dictionary to store all sample data\n",
    "    all_samples_data = {}\n",
    "    gene_ids = None\n",
    "\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for tsv_file in tsv_files:\n",
    "        file_name = tsv_file.name\n",
    "\n",
    "        # Get sample ID from metadata\n",
    "        if file_name not in file_to_sample_mapping:\n",
    "            logger.warning(f\"File {file_name} not found in metadata mapping, skipping\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        sample_id = file_to_sample_mapping[file_name]\n",
    "\n",
    "        # Process the TSV file\n",
    "        sample_data = process_tsv_file(str(tsv_file))\n",
    "\n",
    "        if sample_data is None:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        # Store gene IDs from first successful file\n",
    "        if gene_ids is None:\n",
    "            gene_ids = sample_data.index.tolist()\n",
    "            logger.info(f\"Using gene set from {file_name} with {len(gene_ids)} genes\")\n",
    "\n",
    "        # Ensure consistent gene ordering\n",
    "        sample_data = sample_data.reindex(gene_ids, fill_value=0.0)\n",
    "\n",
    "        # Store the data\n",
    "        all_samples_data[sample_id] = sample_data.values\n",
    "        processed_count += 1\n",
    "\n",
    "        if processed_count % 50 == 0:\n",
    "            logger.info(f\"Processed {processed_count} files...\")\n",
    "\n",
    "    logger.info(f\"Successfully processed {processed_count} files, skipped {skipped_count} files\")\n",
    "\n",
    "    if not all_samples_data:\n",
    "        logger.error(\"No data was successfully processed!\")\n",
    "        return\n",
    "\n",
    "    # Create the combined DataFrame\n",
    "    logger.info(\"Creating combined DataFrame...\")\n",
    "    combined_df = pd.DataFrame(all_samples_data, index=gene_ids)\n",
    "\n",
    "    # Set the index name to 'gene_id'\n",
    "    combined_df.index.name = 'gene_id'\n",
    "\n",
    "    # Ensure proper data types\n",
    "    combined_df = combined_df.astype('float32')  # TPM values as float32 to save space\n",
    "\n",
    "    logger.info(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "    logger.info(f\"Genes (rows): {combined_df.shape[0]}\")\n",
    "    logger.info(f\"Samples (columns): {combined_df.shape[1]}\")\n",
    "    logger.info(f\"Index name: {combined_df.index.name}\")\n",
    "\n",
    "    # Save as parquet\n",
    "    logger.info(f\"Saving to {output_file}...\")\n",
    "    table = pa.Table.from_pandas(combined_df)\n",
    "    pq.write_table(table, output_file, compression='snappy')\n",
    "\n",
    "    logger.info(\"Dataset creation completed successfully!\")\n",
    "\n",
    "    # Print some basic statistics\n",
    "    logger.info(f\"Sample statistics:\")\n",
    "    logger.info(f\"  - Min TPM value: {combined_df.values.min()}\")\n",
    "    logger.info(f\"  - Max TPM value: {combined_df.values.max()}\")\n",
    "    logger.info(f\"  - Mean TPM value: {combined_df.values.mean():.4f}\")\n",
    "    logger.info(f\"  - Median TPM value: {float(pd.Series(combined_df.values.flatten()).median()):.4f}\")\n",
    "\n",
    "\n",
    "def verify_dataset(parquet_file):\n",
    "    logger.info(\"Verifying created dataset...\")\n",
    "\n",
    "    # Load the dataset\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "\n",
    "    # Basic info\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATASET OVERVIEW\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Dataset shape and basic info\n",
    "    info_df = pd.DataFrame({\n",
    "        'Metric': ['Number of Genes (rows)', 'Number of Samples (columns)', 'Data Type', 'Memory Usage (MB)'],\n",
    "        'Value': [df.shape[0], df.shape[1], str(df.dtypes.iloc[0]), f\"{df.memory_usage(deep=True).sum() / 1024**2:.2f}\"]\n",
    "    })\n",
    "    display(info_df)\n",
    "\n",
    "    # Sample preview\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"DATA PREVIEW\")\n",
    "    print(\"=\" * 60)\n",
    "    display(df.iloc[:10, :5])  # First 10 genes, first 5 samples\n",
    "\n",
    "    # Basic statistics\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXPRESSION STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    stats_df = pd.DataFrame({\n",
    "        'Statistic': ['Min TPM', 'Max TPM', 'Mean TPM', 'Median TPM', 'Std TPM',\n",
    "                     'Zero Values (%)', 'Non-zero Values (%)'],\n",
    "        'Value': [\n",
    "            f\"{df.values.min():.4f}\",\n",
    "            f\"{df.values.max():.4f}\",\n",
    "            f\"{df.values.mean():.4f}\",\n",
    "            f\"{np.median(df.values):.4f}\",\n",
    "            f\"{df.values.std():.4f}\",\n",
    "            f\"{(df.values == 0).sum() / df.size * 100:.2f}%\",\n",
    "            f\"{(df.values > 0).sum() / df.size * 100:.2f}%\"\n",
    "        ]\n",
    "    })\n",
    "    display(stats_df)\n",
    "\n",
    "\n",
    "def essential_plots_for_ml(parquet_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ESSENTIAL PLOTS FOR ML PROJECT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Calculate basic statistics\n",
    "    gene_stats = pd.DataFrame({\n",
    "        'Mean_Expression': df.mean(axis=1),\n",
    "        'Zero_Percentage': (df == 0).sum(axis=1) / df.shape[1] * 100,\n",
    "        'CV': df.std(axis=1) / df.mean(axis=1)\n",
    "    })\n",
    "\n",
    "    sample_stats = pd.DataFrame({\n",
    "        'Total_Expression': df.sum(axis=0),\n",
    "        'Expressed_Genes': (df > 0).sum(axis=0)\n",
    "    })\n",
    "\n",
    "    # Create 4 essential plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Plot 1: Expression Distribution (Need for Log Transformation)\n",
    "    axes[0,0].hist(np.log10(df.values.flatten() + 1), bins=100, alpha=0.7, edgecolor='black')\n",
    "    axes[0,0].set_xlabel('Log10(TPM + 1)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].set_title('1. Expression Value Distribution\\n(Determines if log transform needed)')\n",
    "    axes[0,0].axvline(np.log10(1), color='red', linestyle='--', label='TPM = 1')\n",
    "    axes[0,0].legend()\n",
    "\n",
    "    # Plot 2: Gene Sparsity (Feature Filtering)\n",
    "    axes[0,1].hist(gene_stats['Zero_Percentage'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[0,1].set_xlabel('Percentage of Zero Values per Gene')\n",
    "    axes[0,1].set_ylabel('Number of Genes')\n",
    "    axes[0,1].set_title('2. Gene Sparsity Distribution\\n(Guides feature filtering thresholds)')\n",
    "    axes[0,1].axvline(50, color='red', linestyle='--', label='50% threshold')\n",
    "    axes[0,1].axvline(90, color='orange', linestyle='--', label='90% threshold')\n",
    "    axes[0,1].legend()\n",
    "\n",
    "    # Plot 3: Sample Quality (Outlier Detection)\n",
    "    axes[1,0].scatter(sample_stats['Total_Expression']/1000, sample_stats['Expressed_Genes'],\n",
    "                     alpha=0.6, s=30)\n",
    "    axes[1,0].set_xlabel('Total Expression (thousands TPM)')\n",
    "    axes[1,0].set_ylabel('Number of Expressed Genes')\n",
    "    axes[1,0].set_title('3. Sample Quality Check\\n(Outlier detection)')\n",
    "\n",
    "    # Add outlier boundaries\n",
    "    total_q1, total_q3 = sample_stats['Total_Expression'].quantile([0.25, 0.75])\n",
    "    genes_q1, genes_q3 = sample_stats['Expressed_Genes'].quantile([0.25, 0.75])\n",
    "    total_iqr = total_q3 - total_q1\n",
    "    genes_iqr = genes_q3 - genes_q1\n",
    "\n",
    "    axes[1,0].axvline((total_q1 - 1.5 * total_iqr)/1000, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1,0].axvline((total_q3 + 1.5 * total_iqr)/1000, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1,0].axhline(genes_q1 - 1.5 * genes_iqr, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1,0].axhline(genes_q3 + 1.5 * genes_iqr, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Plot 4: Gene Variability (Feature Selection)\n",
    "    # Filter out genes with very low expression for CV calculation\n",
    "    cv_data = gene_stats[(gene_stats['Mean_Expression'] > 1) & (gene_stats['CV'].notna())]['CV']\n",
    "    cv_filtered = cv_data[cv_data < 5]  # Remove extreme outliers for better visualization\n",
    "\n",
    "    axes[1,1].hist(cv_filtered, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1,1].set_xlabel('Coefficient of Variation (CV)')\n",
    "    axes[1,1].set_ylabel('Number of Genes')\n",
    "    axes[1,1].set_title('4. Gene Variability Distribution\\n(Identifies informative features)')\n",
    "    axes[1,1].axvline(1, color='red', linestyle='--', label='CV = 1')\n",
    "    axes[1,1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary statistics for decision making\n",
    "    print(\"\\nKEY STATISTICS FOR ML PREPROCESSING:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    summary_stats = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'Total genes',\n",
    "            'Genes with >50% zeros',\n",
    "            'Genes with >90% zeros',\n",
    "            'Low expression genes (mean < 1 TPM)',\n",
    "            'Highly variable genes (CV > 1)',\n",
    "            'Potential outlier samples'\n",
    "        ],\n",
    "        'Count': [\n",
    "            len(gene_stats),\n",
    "            (gene_stats['Zero_Percentage'] > 50).sum(),\n",
    "            (gene_stats['Zero_Percentage'] > 90).sum(),\n",
    "            (gene_stats['Mean_Expression'] < 1).sum(),\n",
    "            (gene_stats['CV'] > 1).sum(),\n",
    "            len(sample_stats[(sample_stats['Total_Expression'] < total_q1 - 1.5 * total_iqr) |\n",
    "                           (sample_stats['Total_Expression'] > total_q3 + 1.5 * total_iqr)])\n",
    "        ],\n",
    "        'Percentage': [\n",
    "            '100%',\n",
    "            f\"{(gene_stats['Zero_Percentage'] > 50).sum() / len(gene_stats) * 100:.1f}%\",\n",
    "            f\"{(gene_stats['Zero_Percentage'] > 90).sum() / len(gene_stats) * 100:.1f}%\",\n",
    "            f\"{(gene_stats['Mean_Expression'] < 1).sum() / len(gene_stats) * 100:.1f}%\",\n",
    "            f\"{(gene_stats['CV'] > 1).sum() / len(gene_stats) * 100:.1f}%\",\n",
    "            f\"{len(sample_stats[(sample_stats['Total_Expression'] < total_q1 - 1.5 * total_iqr) | (sample_stats['Total_Expression'] > total_q3 + 1.5 * total_iqr)]) / len(sample_stats) * 100:.1f}%\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    display(summary_stats)\n",
    "\n",
    "    return gene_stats, sample_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSV_DIRECTORY = \"./data/tsv\"\n",
    "METADATA_FILE = \"./REQUIRED/metadata.json\"\n",
    "OUTPUT_FILE = \"./data/dataset.pq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the files\n",
    "combine_gdc_files(TSV_DIRECTORY, METADATA_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_dataset(OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
